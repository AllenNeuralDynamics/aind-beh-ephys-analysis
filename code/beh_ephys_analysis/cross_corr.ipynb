{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append('/root/capsule/code/beh_ephys_analysis')\n",
    "from utils.beh_functions import parseSessionID, session_dirs, get_unit_tbl, get_session_tbl\n",
    "from utils.plot_utils import shiftedColorMap, template_reorder, get_gradient_colors\n",
    "from utils.opto_utils import opto_metrics\n",
    "from utils.ephys_functions import cross_corr_train, auto_corr_train, load_drift\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import pickle\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_auto_corr(session, data_type):\n",
    "    bin_long = 0.05\n",
    "    win_long = 2\n",
    "    bin_short = 0.002\n",
    "    win_short = 0.08\n",
    "    session_dir = session_dirs(session)\n",
    "    unit_tbl = get_unit_tbl(session, data_type) \n",
    "    if unit_tbl['LC_range_top'].unique()[0] is None:\n",
    "        print(f'LC range not inferred, probably no opto units in {session}. Exiting.')\n",
    "        return None\n",
    "    session_tbl = get_session_tbl(session)\n",
    "    \n",
    "    session_qm_file = os.path.join(session_dir['processed_dir'], f'{session}_qm.json')\n",
    "    with open(session_qm_file, 'r') as f:\n",
    "        session_qm = json.load(f)\n",
    "    rec_start = session_qm['ephys_cut'][0]\n",
    "    rec_end = session_qm['ephys_cut'][1]\n",
    "\n",
    "    opto_file = os.path.join(session_dir['opto_dir_curated'], \n",
    "                                f'{session}_opto_session.csv')\n",
    "    opto_tbl = pd.read_csv(opto_file)\n",
    "    opto_times = opto_tbl['time'].values\n",
    "\n",
    "    if len(opto_tbl['pre_post'].unique()) > 1:\n",
    "        rec_start = opto_tbl[opto_tbl['pre_post'] == 'pre']['time'].max()\n",
    "        rec_end = opto_tbl[opto_tbl['pre_post'] == 'post']['time'].min()\n",
    "    elif len(opto_tbl['pre_post'].unique()) == 1:\n",
    "        rec_end = opto_tbl['time'].min()\n",
    "\n",
    "    filter = (\n",
    "        (unit_tbl['decoder_label'] != 'artifact') &\n",
    "        (unit_tbl['decoder_label'] != 'noise') &\n",
    "        (unit_tbl['isi_violations_ratio'] < 0.5) &\n",
    "        (unit_tbl['y_loc'] >= unit_tbl['LC_range_bottom'].unique()[0] - 0.1) &\n",
    "        (unit_tbl['y_loc'] <= unit_tbl['LC_range_top'].unique()[0] + 0.1)\n",
    "    )\n",
    "\n",
    "    unit_ids_focus = unit_tbl[filter]['unit_id'].to_list()\n",
    "    print(f'Number of units in LC range: {len(unit_ids_focus)}')\n",
    "\n",
    "    cross_corr_df = pd.DataFrame(columns=['unit_1', 'unit_2', 'cross_corr_long', 'cross_corr_short', 'start', 'end'])\n",
    "    auto_corr_df = pd.DataFrame(columns=['unit', 'auto_corr_long', 'auto_corr_short', 'start', 'end'])\n",
    "    for unit_ind_1, unit_1 in enumerate(unit_ids_focus):\n",
    "        print(f'Processing unit {unit_1}')\n",
    "        spike_times_1 = unit_tbl[unit_tbl['unit_id'] == unit_1]['spike_times'].values[0]\n",
    "        drift_1 = load_drift(session, unit_1, data_type)\n",
    "        start_unit_1 = rec_start\n",
    "        end_unit_1 = rec_end\n",
    "        if drift_1 is not None:\n",
    "            if drift_1['ephys_cut'][0] is not None:\n",
    "                start_unit_1 = max(start_unit_1, drift_1['ephys_cut'][0])\n",
    "            if drift_1['ephys_cut'][1] is not None:\n",
    "                end_unit_1 = min(end_unit_1, drift_1['ephys_cut'][1])\n",
    "        auto_corr_long = auto_corr_train(spike_times_1, bin_long, win_long, start_unit_1, end_unit_1)\n",
    "        auto_corr_short = auto_corr_train(spike_times_1, bin_short, win_short, start_unit_1, end_unit_1)\n",
    "        dist_out_auto = {'unit': unit_1,\n",
    "                    'auto_corr_long': auto_corr_long,\n",
    "                    'auto_corr_short': auto_corr_short,\n",
    "                    'start': start_unit_1,\n",
    "                    'end': end_unit_1}\n",
    "        auto_corr_df = pd.concat([auto_corr_df, pd.DataFrame([dist_out_auto])], ignore_index=True)\n",
    "        for unit_ind_2, unit_2 in enumerate(unit_ids_focus):\n",
    "            cross_corr_long = None\n",
    "            cross_corr_short = None\n",
    "            if unit_ind_1 < unit_ind_2:\n",
    "                print(f'Processing units {unit_1} and {unit_2}')\n",
    "                spike_times_2 = unit_tbl[unit_tbl['unit_id'] == unit_2]['spike_times'].values[0]\n",
    "                drift_2 = load_drift(session, unit_2, data_type)\n",
    "                start = start_unit_1\n",
    "                end = end_unit_1\n",
    "                if drift_2 is not None:\n",
    "                    if drift_2['ephys_cut'][0] is not None:\n",
    "                        start = max(start, drift_2['ephys_cut'][0])\n",
    "                    if drift_2['ephys_cut'][1] is not None:\n",
    "                        end = min(end, drift_2['ephys_cut'][1])\n",
    "                \n",
    "                if start >= end:\n",
    "                    print(f'Skipping units {unit_1} and {unit_2} due to incompatible drift cuts')\n",
    "                    continue\n",
    "                cross_corr_long = cross_corr_train(spike_times_1, spike_times_2, bin_long, win_long, start, end)\n",
    "                cross_corr_short = cross_corr_train(spike_times_1, spike_times_2, bin_short, win_short, start, end)\n",
    "\n",
    "                dist_out = {'unit_1': unit_1,\n",
    "                            'unit_2': unit_2,\n",
    "                            'cross_corr_long': cross_corr_long,\n",
    "                            'cross_corr_short': cross_corr_short,\n",
    "                            'start': start,\n",
    "                            'end': end}\n",
    "                # Append the result to the cross_corr_df dataframe\n",
    "                if cross_corr_long is not None or cross_corr_short is not None:\n",
    "                    cross_corr_df = pd.concat([cross_corr_df, pd.DataFrame([dist_out])], ignore_index=True)\n",
    "    # Save the results to pickle files\n",
    "    cross_corr_file = os.path.join(session_dir[f'ephys_processed_dir_{data_type}'], f'{session}_{data_type}_cross_corr.pkl')\n",
    "    auto_corr_file = os.path.join(session_dir[f'ephys_processed_dir_{data_type}'], f'{session}_{data_type}_auto_corr.pkl')\n",
    "    with open(cross_corr_file, 'wb') as f:\n",
    "        pickle.dump(cross_corr_df, f)\n",
    "    with open(auto_corr_file, 'wb') as f:\n",
    "        pickle.dump(auto_corr_df, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are multiple recordings in the curated nwb directory. Picked one with units.\n",
      "There are multiple recordings in the curated nwb directory. Picked one with units.\n",
      "LC range not inferred, probably no opto units in ecephys_713854_2024-03-08_14-54-25. Exiting.\n"
     ]
    }
   ],
   "source": [
    "cross_auto_corr('ecephys_713854_2024-03-08_14-54-25', 'curated')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting ecephys_713854_2024-03-05_12-01-40\n",
      "/root/capsule/data/ecephys_713854_2024-03-05_12-01-40_sorted_curated/curated/experiment1_Record Node 104#Neuropix-PXI-100.ProbeA_recording1\n",
      "Starting ecephys_717120_2024-03-07_12-12-02\n",
      "/root/capsule/data/ecephys_717120_2024-03-07_12-12-02_sorted_curated/curated/experiment1_Record Node 104#Neuropix-PXI-100.ProbeA_recording1\n",
      "Starting ecephys_713854_2024-03-05_13-31-20\n",
      "/root/capsule/data/ecephys_713854_2024-03-05_13-31-20_sorted_curated/curated/experiment1_Record Node 104#Neuropix-PXI-100.ProbeA_recording1\n",
      "Starting ecephys_713854_2024-03-05_13-01-09\n",
      "/root/capsule/data/ecephys_713854_2024-03-05_13-01-09_sorted_curated/curated/experiment1_Record Node 104#Neuropix-PXI-100.ProbeA_recording1\n",
      "Starting ecephys_713854_2024-03-08_15-43-01\n",
      "/root/capsule/data/ecephys_713854_2024-03-08_15-43-01_sorted_curated/curated/experiment1_Record Node 104#Neuropix-PXI-100.ProbeA_recording1\n",
      "Starting ecephys_713854_2024-03-08_16-20-33\n",
      "/root/capsule/data/ecephys_713854_2024-03-08_16-20-33_sorted_curated/curated/experiment1_Record Node 104#Neuropix-PXI-100.ProbeA_recording1\n",
      "Starting ecephys_717120_2024-03-06_12-54-27\n",
      "/root/capsule/data/ecephys_717120_2024-03-06_12-54-27_sorted_curated/curated/experiment1_Record Node 104#Neuropix-PXI-100.ProbeA_recording1\n",
      "Number of units in LC range: 7\n",
      "Number of units in LC range: 61\n",
      "Processing unit 52\n",
      "Processing unit 6\n",
      "Number of units in LC range: 24\n",
      "Processing unit 0\n",
      "Number of units in LC range: 19\n",
      "Processing unit 4\n",
      "LC range not inferred, probably no opto units in ecephys_713854_2024-03-08_16-20-33. Exiting.\n",
      "Number of units in LC range: 16\n",
      "Finished ecephys_713854_2024-03-08_16-20-33\n",
      "Processing unit 3\n",
      "Number of units in LC range: 40\n",
      "Processing unit 21\n",
      "Starting ecephys_713854_2024-03-08_17-15-58\n",
      "There is no nwb file in the curated directory.\n",
      "None\n",
      "No curated data found for ecephys_713854_2024-03-08_17-15-58\n",
      "Starting ecephys_684930_2023-09-27_10-04-04\n",
      "/root/capsule/data/ecephys_684930_2023-09-27_10-04-04_sorted_curated/curated/experiment1_Record Node 104#Neuropix-PXI-100.ProbeA-AP_recording1\n",
      "Processing units 6 and 11\n",
      "Processing units 52 and 53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_16383/1956190056.py:61: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "/tmp/ipykernel_16383/1956190056.py:61: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "/tmp/ipykernel_16383/1956190056.py:61: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "/tmp/ipykernel_16383/1956190056.py:61: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "/tmp/ipykernel_16383/1956190056.py:61: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing units 0 and 3\n",
      "Processing units 3 and 4\n",
      "Processing units 4 and 5\n",
      "Starting ecephys_717120_2024-03-06_12-23-53\n",
      "/root/capsule/data/ecephys_717120_2024-03-06_12-23-53_sorted_curated/curated/experiment1_Record Node 104#Neuropix-PXI-100.ProbeA_recording1\n",
      "Number of units in LC range: 124\n",
      "Processing unit 22.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_16383/1956190056.py:61: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "/tmp/ipykernel_16383/1956190056.py:91: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "/tmp/ipykernel_16383/1956190056.py:91: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "/tmp/ipykernel_16383/1956190056.py:91: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "/tmp/ipykernel_16383/1956190056.py:91: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing units 21 and 24\n",
      "LC range not inferred, probably no opto units in ecephys_717120_2024-03-06_12-23-53. Exiting.\n",
      "Starting ecephys_713854_2024-03-08_14-54-25\n",
      "There are multiple recordings in the curated nwb directory. Picked one with units.\n",
      "Finished ecephys_717120_2024-03-06_12-23-53\n",
      "/root/capsule/data/ecephys_713854_2024-03-08_14-54-25_sorted_curated/curated/experiment1_Record Node 104#Neuropix-PXI-100.ProbeA_recording1\n",
      "There are multiple recordings in the curated nwb directory. Picked one with units.\n",
      "There are multiple recordings in the curated nwb directory. Picked one with units.\n",
      "Processing units 6 and 12\n",
      "Processing units 3 and 5\n",
      "Processing units 52 and 54\n",
      "Processing units 0 and 4\n",
      "Processing units 3 and 7\n",
      "Starting ecephys_684930_2023-09-28_11-45-27\n",
      "/root/capsule/data/ecephys_684930_2023-09-28_11-45-27_sorted_curated/curated/experiment1_Record Node 104#Neuropix-PXI-100.ProbeA-AP_recording1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_16383/1956190056.py:91: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing units 4 and 6\n",
      "LC range not inferred, probably no opto units in ecephys_713854_2024-03-08_14-54-25. Exiting.\n",
      "Finished ecephys_713854_2024-03-08_14-54-25\n",
      "Starting ecephys_684930_2023-09-28_12-44-15\n",
      "/root/capsule/data/ecephys_684930_2023-09-28_12-44-15_sorted_curated/curated/experiment1_Record Node 104#Neuropix-PXI-100.ProbeA-AP_recording1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_16383/1956190056.py:91: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "/tmp/ipykernel_16383/1956190056.py:61: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing units 21 and 26\n",
      "Processing units 6 and 13\n",
      "Number of units in LC range: 166\n",
      "Processing unit 13.0\n",
      "Processing units 22.0 and 26.0\n",
      "Processing units 0 and 9\n",
      "Processing units 3 and 10\n",
      "Processing units 52 and 59\n",
      "Processing units 4 and 12\n",
      "Number of units in LC range: 114\n",
      "Processing unit 5.0\n",
      "Processing units 6 and 15\n",
      "Processing units 3 and 13\n",
      "Processing units 21 and 27\n",
      "Processing units 0 and 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_16383/1956190056.py:61: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "/tmp/ipykernel_16383/1956190056.py:91: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "/tmp/ipykernel_16383/1956190056.py:61: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing units 5.0 and 13.0\n",
      "Processing units 4 and 13\n",
      "Processing units 22.0 and 27.0\n",
      "Processing units 13.0 and 14.0\n",
      "Processing units 52 and 62\n",
      "Processing units 6 and 16\n",
      "Processing units 3 and 14\n",
      "Processing units 0 and 11\n",
      "Processing units 21 and 31\n",
      "Processing units 4 and 16\n",
      "Processing units 5.0 and 14.0\n",
      "Processing units 3 and 18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_16383/1956190056.py:91: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing units 52 and 64\n",
      "Processing units 6 and 18\n",
      "Processing units 22.0 and 29.0\n",
      "Processing units 0 and 12\n",
      "Processing units 13.0 and 15.0\n",
      "Skipping units 13.0 and 15.0 due to incompatible drift cuts\n",
      "Processing units 13.0 and 16.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_16383/1956190056.py:91: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing units 5.0 and 15.0\n",
      "Processing units 21 and 32\n",
      "Processing units 3 and 20\n",
      "Processing units 4 and 17\n",
      "Processing units 52 and 65\n",
      "Processing units 6 and 19\n",
      "Processing units 0 and 15\n",
      "Processing units 5.0 and 16.0\n",
      "Processing units 22.0 and 32.0\n",
      "Processing units 3 and 21\n",
      "Processing units 21 and 33\n",
      "Processing units 13.0 and 19.0\n",
      "Processing unit 53\n",
      "Processing units 4 and 18\n",
      "Processing units 0 and 17\n",
      "Processing units 6 and 21\n",
      "Processing units 5.0 and 18.0\n",
      "Processing units 3 and 24\n",
      "Processing units 21 and 35\n",
      "Processing units 0 and 19\n",
      "Processing units 4 and 22\n",
      "Processing units 6 and 22\n",
      "Processing units 22.0 and 34.0\n",
      "Processing units 5.0 and 22.0\n",
      "Processing units 3 and 126\n",
      "Processing units 53 and 54\n",
      "Processing units 21 and 36\n",
      "Processing units 13.0 and 22.0\n",
      "Processing units 6 and 24\n",
      "Processing units 4 and 26\n",
      "Processing units 0 and 22\n",
      "Processing units 3 and 165\n",
      "Processing units 5.0 and 23.0\n",
      "Processing units 53 and 59\n",
      "Processing units 21 and 37\n",
      "Processing units 22.0 and 35.0\n",
      "Processing units 6 and 26\n",
      "Processing units 0 and 24\n",
      "Processing units 5.0 and 27.0\n",
      "Processing units 13.0 and 24.0\n",
      "Processing units 4 and 28\n",
      "Processing units 3 and 166\n",
      "Processing units 53 and 62\n",
      "Processing units 21 and 40\n",
      "Processing units 6 and 27\n",
      "Processing units 5.0 and 29.0\n",
      "Processing units 4 and 29\n",
      "Processing units 3 and 172\n",
      "Processing units 0 and 27\n",
      "Processing units 13.0 and 25.0\n",
      "Processing units 22.0 and 36.0\n",
      "Processing units 6 and 29\n",
      "Processing units 21 and 41\n",
      "Processing units 53 and 64\n",
      "Processing units 3 and 173\n",
      "Processing units 4 and 31\n",
      "Processing units 5.0 and 30.0\n",
      "Processing units 0 and 28\n",
      "Processing units 21 and 43\n",
      "Processing units 6 and 30\n",
      "Processing units 13.0 and 26.0\n",
      "Processing unit 4\n",
      "Processing units 53 and 65\n",
      "Processing units 4 and 35\n",
      "Processing units 22.0 and 37.0\n",
      "Processing units 5.0 and 32.0\n",
      "Processing units 22.0 and 40.0\n",
      "Processing units 0 and 29\n",
      "Processing units 22.0 and 42.0\n",
      "Processing units 21 and 44\n",
      "Processing units 4 and 5\n",
      "Processing units 4 and 7\n",
      "Processing units 6 and 32\n",
      "Processing units 5.0 and 33.0\n",
      "Processing units 4 and 176\n",
      "Processing unit 54\n",
      "Processing units 13.0 and 27.0\n",
      "Processing units 0 and 30\n",
      "Processing units 21 and 45\n",
      "Processing units 4 and 10\n",
      "Processing units 5.0 and 34.0\n",
      "Processing units 4 and 182\n",
      "Processing units 54 and 59\n",
      "Processing units 6 and 33\n",
      "Processing units 22.0 and 44.0\n",
      "Processing units 13.0 and 28.0\n",
      "Processing units 0 and 134\n",
      "Processing units 4 and 13\n",
      "Processing units 5.0 and 35.0\n",
      "Processing units 21 and 47\n",
      "Processing units 4 and 184\n",
      "Processing units 6 and 36\n",
      "Processing units 54 and 62\n",
      "Processing units 4 and 14\n",
      "Processing units 22.0 and 46.0\n",
      "Processing units 5.0 and 36.0\n",
      "Processing units 13.0 and 30.0\n",
      "Processing units 22.0 and 47.0\n",
      "Processing units 0 and 137\n",
      "Processing units 4 and 219\n",
      "Processing units 6 and 37\n",
      "Processing units 21 and 49\n",
      "Processing units 4 and 18\n",
      "Processing units 5.0 and 41.0\n",
      "Processing units 54 and 64\n",
      "Processing units 0 and 141\n",
      "Processing units 4 and 232\n",
      "Processing units 6 and 38\n",
      "Processing units 13.0 and 32.0\n",
      "Processing units 22.0 and 48.0\n",
      "Processing units 4 and 20\n",
      "Processing units 5.0 and 42.0\n",
      "Processing units 54 and 65\n",
      "Processing units 21 and 50\n",
      "Processing unit 5\n",
      "Processing units 6 and 39\n",
      "Processing units 4 and 21\n",
      "Processing units 0 and 143\n",
      "Processing units 5.0 and 45.0\n",
      "Processing unit 59\n",
      "Processing units 13.0 and 35.0\n",
      "Processing units 22.0 and 49.0\n",
      "Processing units 4 and 24\n",
      "Processing units 6 and 40\n",
      "Processing units 21 and 51\n",
      "Processing units 5 and 6\n",
      "Processing units 5.0 and 49.0\n",
      "Processing units 0 and 161\n",
      "Processing units 4 and 126\n",
      "Processing units 59 and 62\n",
      "Processing units 6 and 41\n",
      "Processing units 13.0 and 39.0\n",
      "Processing units 5.0 and 50.0\n",
      "Processing units 21 and 52\n",
      "Processing units 22.0 and 50.0\n",
      "Processing units 0 and 167\n",
      "Processing units 5 and 12\n",
      "Processing units 4 and 165\n",
      "Processing units 6 and 42\n",
      "Processing units 59 and 64\n",
      "Processing units 21 and 53\n",
      "Processing units 0 and 169\n",
      "Processing units 5.0 and 51.0\n",
      "Processing units 5 and 13\n",
      "Processing units 13.0 and 40.0\n",
      "Processing units 22.0 and 55.0\n",
      "Processing units 4 and 166\n",
      "Processing units 59 and 65\n",
      "Processing units 6 and 43\n",
      "Processing units 21 and 55\n",
      "Processing units 5.0 and 56.0\n",
      "Processing units 0 and 171\n",
      "Processing units 5 and 16\n",
      "Processing units 4 and 172\n",
      "Processing units 6 and 47\n",
      "Processing unit 62\n",
      "Processing units 13.0 and 42.0\n",
      "Processing units 21 and 58\n",
      "Processing units 22.0 and 57.0\n",
      "Processing units 5.0 and 58.0\n",
      "Processing units 5 and 17\n",
      "Processing unit 3\n",
      "Processing units 4 and 173\n",
      "Processing units 62 and 64\n",
      "Processing units 21 and 59\n",
      "Processing units 6 and 48\n",
      "Processing units 13.0 and 43.0\n",
      "Processing units 5.0 and 65.0\n",
      "Processing unit 5\n",
      "Processing units 5 and 7\n",
      "Processing units 5 and 18\n",
      "Processing units 5 and 10\n",
      "Processing units 3 and 4\n",
      "Processing units 5 and 13\n",
      "Processing units 5 and 14\n",
      "Processing units 5 and 18\n",
      "Processing units 5 and 20\n",
      "Processing units 5 and 21\n",
      "Processing units 62 and 65\n",
      "Processing units 5 and 24\n",
      "Processing units 5 and 126\n",
      "Processing units 5 and 165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/numpy/lib/_function_base_impl.py:2999: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[:, None]\n",
      "/opt/conda/lib/python3.10/site-packages/numpy/lib/_function_base_impl.py:3000: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[None, :]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing units 22.0 and 58.0\n",
      "Processing units 5 and 166\n",
      "Processing units 21 and 60\n",
      "Processing units 5 and 172\n",
      "Processing units 5 and 173\n",
      "Processing units 6 and 49\n",
      "Processing unit 7\n",
      "Processing units 5.0 and 67.0\n",
      "Processing units 3 and 9\n",
      "Processing units 5 and 22\n",
      "Processing unit 64\n",
      "Processing units 13.0 and 44.0\n",
      "Processing units 6 and 51\n",
      "Processing units 7 and 10\n",
      "Processing units 5.0 and 69.0\n",
      "Processing units 21 and 62\n",
      "Processing units 22.0 and 59.0\n",
      "Processing units 5 and 26\n",
      "Processing units 3 and 10\n",
      "Processing units 22.0 and 64.0\n",
      "Processing units 64 and 65\n",
      "Processing units 7 and 13\n",
      "Processing units 6 and 52\n",
      "Processing units 21 and 63\n",
      "Processing units 5.0 and 70.0\n",
      "Processing units 5 and 28\n",
      "Processing units 3 and 11\n",
      "Processing unit 65\n",
      "Processing units 13.0 and 45.0\n",
      "Processing units 7 and 14\n",
      "Processing units 22.0 and 65.0\n",
      "Processing units 6 and 53\n",
      "Processing units 5.0 and 71.0\n",
      "Processing units 21 and 64\n",
      "Processing units 3 and 12\n",
      "Finished ecephys_713854_2024-03-05_12-01-40\n",
      "Processing units 5 and 29\n",
      "Starting ecephys_687697_2023-09-15_11-30-06\n",
      "Processing units 7 and 18\n",
      "/root/capsule/data/ecephys_687697_2023-09-15_11-30-06_sorted_curated/curated/experiment1_Record Node 104#Neuropix-PXI-100.ProbeA-AP_recording1\n",
      "Processing units 13.0 and 46.0\n",
      "Processing units 6 and 54\n",
      "Processing units 3 and 15\n",
      "Processing units 21 and 65\n",
      "Processing units 22.0 and 66.0\n",
      "Processing units 5 and 31\n",
      "Processing units 5.0 and 72.0\n",
      "Processing units 7 and 20\n",
      "Number of units in LC range: 39\n",
      "Processing unit 0.0\n",
      "Processing units 6 and 55\n",
      "Processing units 3 and 17\n",
      "Processing units 13.0 and 47.0\n",
      "Processing units 21 and 66\n",
      "Processing units 7 and 21\n",
      "Processing units 5.0 and 73.0\n",
      "Processing units 5 and 35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_16383/1956190056.py:61: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing units 0.0 and 2.0\n",
      "Processing units 22.0 and 68.0\n",
      "Processing units 6 and 56\n",
      "Processing units 3 and 19\n",
      "Processing units 21 and 133\n",
      "Processing units 7 and 24\n",
      "Processing units 5.0 and 75.0\n",
      "Processing units 13.0 and 49.0\n",
      "Processing units 7 and 126\n",
      "Processing units 3 and 22\n",
      "Processing units 5 and 176\n",
      "Processing units 21 and 134\n",
      "Processing units 22.0 and 69.0\n",
      "Processing units 6 and 57\n",
      "Processing units 0.0 and 4.0\n",
      "Processing units 5.0 and 78.0\n",
      "Skipping units 0.0 and 4.0 due to incompatible drift cuts\n",
      "Processing units 0.0 and 6.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_16383/1956190056.py:91: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping units 0.0 and 6.0 due to incompatible drift cuts\n",
      "Processing units 0.0 and 7.0\n",
      "Processing units 13.0 and 50.0\n",
      "Processing units 7 and 165\n",
      "Processing units 5 and 182\n",
      "Processing units 3 and 24\n",
      "Processing units 6 and 58\n",
      "Processing units 21 and 137\n",
      "Processing units 5.0 and 79.0\n",
      "Processing units 7 and 166\n",
      "Processing units 0.0 and 18.0\n",
      "Processing units 22.0 and 70.0\n",
      "Processing units 13.0 and 51.0\n",
      "Processing units 5 and 184\n",
      "Processing units 3 and 27\n",
      "Processing units 6 and 59\n",
      "Processing units 7 and 172\n",
      "Processing units 21 and 138\n",
      "Processing units 5.0 and 80.0\n",
      "Processing units 5 and 219\n",
      "Processing units 3 and 28\n",
      "Processing units 22.0 and 72.0\n",
      "Processing units 13.0 and 52.0\n",
      "Processing units 6 and 60\n",
      "Processing units 7 and 173\n",
      "Processing units 0.0 and 22.0\n",
      "Processing units 21 and 145\n",
      "Processing units 5.0 and 83.0\n",
      "Processing units 3 and 29\n",
      "Processing units 6 and 64\n",
      "Processing units 5 and 232\n",
      "Processing unit 10\n",
      "Processing units 21 and 146\n",
      "Processing units 22.0 and 75.0\n",
      "Processing units 0.0 and 23.0\n",
      "Processing units 5.0 and 84.0\n",
      "Processing units 13.0 and 53.0\n",
      "Processing units 6 and 65\n",
      "Processing units 3 and 30\n",
      "Processing units 10 and 13\n",
      "Processing unit 6\n",
      "Processing units 21 and 148\n",
      "Processing units 6 and 66\n",
      "Processing units 3 and 134\n",
      "Processing units 5.0 and 85.0\n",
      "Processing units 22.0 and 78.0\n",
      "Processing units 0.0 and 26.0\n",
      "Processing units 10 and 14\n",
      "Processing units 6 and 12\n",
      "Processing units 13.0 and 54.0\n",
      "Processing units 21 and 149\n",
      "Processing units 3 and 137\n",
      "Processing units 6 and 67\n",
      "Processing units 5.0 and 86.0\n",
      "Processing units 10 and 18\n",
      "Processing units 6 and 13\n",
      "Processing units 0.0 and 29.0\n",
      "Processing units 22.0 and 79.0\n",
      "Processing units 21 and 151\n",
      "Processing units 6 and 69\n",
      "Processing units 3 and 141\n",
      "Processing units 10 and 20\n",
      "Processing units 13.0 and 55.0\n",
      "Processing units 6 and 16\n",
      "Processing units 5.0 and 87.0\n",
      "Processing units 6 and 70\n",
      "Processing units 3 and 143\n",
      "Processing units 21 and 152\n",
      "Processing units 10 and 21\n",
      "Processing units 0.0 and 31.0\n",
      "Processing units 6 and 17\n",
      "Processing units 5.0 and 90.0\n",
      "Processing units 22.0 and 81.0\n",
      "Processing units 10 and 24\n",
      "Processing units 3 and 161\n",
      "Processing units 6 and 71\n",
      "Processing units 13.0 and 58.0\n",
      "Processing unit 24\n",
      "Processing units 10 and 126\n",
      "Processing units 0.0 and 34.0\n",
      "Processing units 3 and 167\n",
      "Processing units 6 and 18\n",
      "Processing units 5.0 and 91.0\n",
      "Processing units 22.0 and 83.0\n",
      "Processing units 24 and 26\n",
      "Processing units 6 and 107\n",
      "Processing units 13.0 and 59.0\n",
      "Processing units 10 and 165\n",
      "Processing units 3 and 169\n",
      "Processing units 6 and 22\n",
      "Processing units 5.0 and 92.0\n",
      "Processing units 6 and 108\n",
      "Processing units 0.0 and 37.0\n",
      "Processing units 10 and 166\n",
      "Processing units 24 and 27\n",
      "Processing units 3 and 171\n",
      "Processing units 13.0 and 61.0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/root/capsule/code/beh_ephys_analysis/cross_corr.ipynb Cell 4\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell://codeocean.allenneuraldynamics.org/root/capsule/code/beh_ephys_analysis/cross_corr.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=22'>23</a>\u001b[0m         \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mNo curated data found for \u001b[39m\u001b[39m{\u001b[39;00msession\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m) \n\u001b[1;32m     <a href='vscode-notebook-cell://codeocean.allenneuraldynamics.org/root/capsule/code/beh_ephys_analysis/cross_corr.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=23'>24</a>\u001b[0m     \u001b[39m# elif session\\_dir['curated_dir_raw'] is not None:\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://codeocean.allenneuraldynamics.org/root/capsule/code/beh_ephys_analysis/cross_corr.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=24'>25</a>\u001b[0m     \u001b[39m#     data_type = 'raw' \u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://codeocean.allenneuraldynamics.org/root/capsule/code/beh_ephys_analysis/cross_corr.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=25'>26</a>\u001b[0m     \u001b[39m#     opto_tagging_df_sess = opto_plotting_session(session, data_type, target, resp_thresh=resp_thresh, lat_thresh=lat_thresh, target_unit_ids= None, plot = True, save=True)\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell://codeocean.allenneuraldynamics.org/root/capsule/code/beh_ephys_analysis/cross_corr.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=26'>27</a>\u001b[0m Parallel(n_jobs\u001b[39m=\u001b[39;49m\u001b[39m-\u001b[39;49m\u001b[39m8\u001b[39;49m)(\n\u001b[1;32m     <a href='vscode-notebook-cell://codeocean.allenneuraldynamics.org/root/capsule/code/beh_ephys_analysis/cross_corr.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=27'>28</a>\u001b[0m     delayed(process)(session, data_type) \n\u001b[1;32m     <a href='vscode-notebook-cell://codeocean.allenneuraldynamics.org/root/capsule/code/beh_ephys_analysis/cross_corr.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=28'>29</a>\u001b[0m     \u001b[39mfor\u001b[39;49;00m session \u001b[39min\u001b[39;49;00m session_list\n\u001b[1;32m     <a href='vscode-notebook-cell://codeocean.allenneuraldynamics.org/root/capsule/code/beh_ephys_analysis/cross_corr.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=29'>30</a>\u001b[0m )\n\u001b[1;32m     <a href='vscode-notebook-cell://codeocean.allenneuraldynamics.org/root/capsule/code/beh_ephys_analysis/cross_corr.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=31'>32</a>\u001b[0m \u001b[39m# process('behavior_754897_2025-03-13_11-20-42', data_type)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://codeocean.allenneuraldynamics.org/root/capsule/code/beh_ephys_analysis/cross_corr.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=32'>33</a>\u001b[0m \u001b[39m# for session, probe in zip(session_list, probe_list):\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://codeocean.allenneuraldynamics.org/root/capsule/code/beh_ephys_analysis/cross_corr.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=33'>34</a>\u001b[0m \u001b[39m#     process(session, data_type, probe)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://codeocean.allenneuraldynamics.org/root/capsule/code/beh_ephys_analysis/cross_corr.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=34'>35</a>\u001b[0m \u001b[39m#     plt.close('all')\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/joblib/parallel.py:2072\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   2066\u001b[0m \u001b[39m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[1;32m   2067\u001b[0m \u001b[39m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[1;32m   2068\u001b[0m \u001b[39m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[1;32m   2069\u001b[0m \u001b[39m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[1;32m   2070\u001b[0m \u001b[39mnext\u001b[39m(output)\n\u001b[0;32m-> 2072\u001b[0m \u001b[39mreturn\u001b[39;00m output \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreturn_generator \u001b[39melse\u001b[39;00m \u001b[39mlist\u001b[39;49m(output)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/joblib/parallel.py:1682\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[0;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[1;32m   1679\u001b[0m     \u001b[39myield\u001b[39;00m\n\u001b[1;32m   1681\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend\u001b[39m.\u001b[39mretrieval_context():\n\u001b[0;32m-> 1682\u001b[0m         \u001b[39myield from\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_retrieve()\n\u001b[1;32m   1684\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mGeneratorExit\u001b[39;00m:\n\u001b[1;32m   1685\u001b[0m     \u001b[39m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[1;32m   1686\u001b[0m     \u001b[39m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[1;32m   1687\u001b[0m     \u001b[39m# the user if necessary.\u001b[39;00m\n\u001b[1;32m   1688\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exception \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/joblib/parallel.py:1800\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1789\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreturn_ordered:\n\u001b[1;32m   1790\u001b[0m     \u001b[39m# Case ordered: wait for completion (or error) of the next job\u001b[39;00m\n\u001b[1;32m   1791\u001b[0m     \u001b[39m# that have been dispatched and not retrieved yet. If no job\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1795\u001b[0m     \u001b[39m# control only have to be done on the amount of time the next\u001b[39;00m\n\u001b[1;32m   1796\u001b[0m     \u001b[39m# dispatched job is pending.\u001b[39;00m\n\u001b[1;32m   1797\u001b[0m     \u001b[39mif\u001b[39;00m (nb_jobs \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m) \u001b[39mor\u001b[39;00m (\n\u001b[1;32m   1798\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mget_status(timeout\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtimeout) \u001b[39m==\u001b[39m TASK_PENDING\n\u001b[1;32m   1799\u001b[0m     ):\n\u001b[0;32m-> 1800\u001b[0m         time\u001b[39m.\u001b[39;49msleep(\u001b[39m0.01\u001b[39;49m)\n\u001b[1;32m   1801\u001b[0m         \u001b[39mcontinue\u001b[39;00m\n\u001b[1;32m   1803\u001b[0m \u001b[39melif\u001b[39;00m nb_jobs \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m   1804\u001b[0m     \u001b[39m# Case unordered: jobs are added to the list of jobs to\u001b[39;00m\n\u001b[1;32m   1805\u001b[0m     \u001b[39m# retrieve `self._jobs` only once completed or in error, which\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1811\u001b[0m     \u001b[39m# timeouts before any other dispatched job has completed and\u001b[39;00m\n\u001b[1;32m   1812\u001b[0m     \u001b[39m# been added to `self._jobs` to be retrieved.\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "session_assets = pd.read_csv('/root/capsule/code/data_management/session_assets.csv')\n",
    "session_list = session_assets['session_id']\n",
    "probe_list = session_assets['probe']\n",
    "probe_list = [probe for probe, session in zip(probe_list, session_list) if isinstance(session, str)]\n",
    "session_list = [session for session in session_list if isinstance(session, str)]    \n",
    "from joblib import Parallel, delayed\n",
    "data_type = 'curated'\n",
    "def process(session, data_type): \n",
    "    print(f'Starting {session}')\n",
    "    session_dir = session_dirs(session)\n",
    "    # if os.path.exists(os.path.join(session_dir['beh_fig_dir'], f'{session}.nwb')):\n",
    "    print(session_dir[f'curated_dir_{data_type}'])\n",
    "    if session_dir[f'curated_dir_{data_type}'] is not None:\n",
    "        try:\n",
    "            # plot_ephys_probe(session, data_type=data_type, probe=probe) \n",
    "            cross_auto_corr(session, data_type)\n",
    "            plt.close('all')\n",
    "            print(f'Finished {session}')\n",
    "        except:\n",
    "            print(f'Error processing {session}')\n",
    "            plt.close('all')\n",
    "    else: \n",
    "        print(f'No curated data found for {session}') \n",
    "    # elif session\\_dir['curated_dir_raw'] is not None:\n",
    "    #     data_type = 'raw' \n",
    "    #     opto_tagging_df_sess = opto_plotting_session(session, data_type, target, resp_thresh=resp_thresh, lat_thresh=lat_thresh, target_unit_ids= None, plot = True, save=True)\n",
    "Parallel(n_jobs=-8)(\n",
    "    delayed(process)(session, data_type) \n",
    "    for session in session_list\n",
    ")\n",
    "\n",
    "# process('behavior_754897_2025-03-13_11-20-42', data_type)\n",
    "# for session, probe in zip(session_list, probe_list):\n",
    "#     process(session, data_type, probe)\n",
    "#     plt.close('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ecephys_713854_2024-03-05_12-01-40',\n",
       " 'ecephys_713854_2024-03-05_13-01-09',\n",
       " 'ecephys_713854_2024-03-05_13-31-20',\n",
       " 'ecephys_717120_2024-03-06_12-23-53',\n",
       " 'ecephys_717120_2024-03-06_12-54-27',\n",
       " 'ecephys_717120_2024-03-07_12-12-02',\n",
       " 'ecephys_713854_2024-03-08_14-54-25',\n",
       " 'ecephys_713854_2024-03-08_15-43-01',\n",
       " 'ecephys_713854_2024-03-08_16-20-33',\n",
       " 'ecephys_713854_2024-03-08_17-15-58',\n",
       " 'ecephys_684930_2023-09-27_10-04-04',\n",
       " 'ecephys_684930_2023-09-28_11-45-27',\n",
       " 'ecephys_684930_2023-09-28_12-44-15',\n",
       " 'ecephys_687697_2023-09-15_11-30-06',\n",
       " 'ecephys_687697_2023-09-15_12-36-06',\n",
       " 'ecephys_691893_2023-10-05_12-46-57',\n",
       " 'ecephys_691893_2023-10-06_13-48-18',\n",
       " 'behavior_716325_2024-05-29_10-33-32',\n",
       " 'behavior_716325_2024-05-30_11-33-46',\n",
       " 'behavior_716325_2024-05-31_10-31-14',\n",
       " 'behavior_716325_2024-06-01_09-25-37',\n",
       " 'behavior_717121_2024-06-11_10-23-31',\n",
       " 'behavior_717121_2024-06-13_12-21-20',\n",
       " 'behavior_717121_2024-06-14_10-23-49',\n",
       " 'behavior_717121_2024-06-15_10-00-58',\n",
       " 'behavior_717121_2024-06-16_11-45-02',\n",
       " 'behavior_717259_2024-06-25_10-09-25',\n",
       " 'behavior_717259_2024-06-26_10-23-07',\n",
       " 'behavior_717259_2024-06-28_11-17-19',\n",
       " 'behavior_717263_2024-07-23_11-46-42',\n",
       " 'behavior_717263_2024-07-24_10-40-05',\n",
       " 'behavior_717263_2024-07-25_10-02-21',\n",
       " 'behavior_714116_2024-08-27_11-29-48',\n",
       " 'behavior_714116_2024-08-28_12-11-55',\n",
       " 'behavior_714116_2024-08-29_11-46-43',\n",
       " 'behavior_722832_2024-09-13_11-55-58',\n",
       " 'behavior_724172_2024-10-01_11-20-11',\n",
       " 'behavior_724172_2024-10-03_11-02-53',\n",
       " 'behavior_739970_2024-10-15_10-04-12',\n",
       " 'behavior_739970_2024-10-16_12-15-24',\n",
       " 'behavior_739977_2024-10-24_12-58-26',\n",
       " 'behavior_744779_2024-11-12_13-10-14',\n",
       " 'behavior_744779_2024-11-13_13-35-38',\n",
       " 'behavior_744779_2024-11-14_13-13-37',\n",
       " 'behavior_744779_2024-11-15_12-54-11',\n",
       " 'behavior_751004_2024-12-19_11-50-37',\n",
       " 'behavior_751004_2024-12-20_13-26-11',\n",
       " 'behavior_751004_2024-12-21_13-28-28',\n",
       " 'behavior_751004_2024-12-22_13-09-17',\n",
       " 'behavior_751004_2024-12-23_14-20-03',\n",
       " 'behavior_751769_2025-01-16_11-32-05',\n",
       " 'behavior_751769_2025-01-17_11-37-39',\n",
       " 'behavior_751769_2025-01-18_10-15-25',\n",
       " 'behavior_758017_2025-02-04_11-57-38',\n",
       " 'behavior_758017_2025-02-05_11-42-34',\n",
       " 'behavior_758017_2025-02-06_11-26-14',\n",
       " 'behavior_758017_2025-02-07_14-11-08',\n",
       " 'behavior_751766_2025-02-11_11-53-38',\n",
       " 'behavior_751766_2025-02-13_11-31-21',\n",
       " 'behavior_751766_2025-02-14_11-37-11',\n",
       " 'behavior_751766_2025-02-15_12-08-11',\n",
       " 'behavior_751181_2025-02-25_12-12-35',\n",
       " 'behavior_751181_2025-02-26_11-51-19',\n",
       " 'behavior_751181_2025-02-27_11-24-47',\n",
       " 'behavior_754897_2025-03-11_12-07-41',\n",
       " 'behavior_754897_2025-03-12_12-23-15',\n",
       " 'behavior_754897_2025-03-13_11-20-42',\n",
       " 'behavior_754897_2025-03-14_11-28-53',\n",
       " 'behavior_754897_2025-03-15_11-32-18',\n",
       " 'behavior_758018_2025-03-19_11-16-44',\n",
       " 'behavior_758018_2025-03-20_11-53-05',\n",
       " 'behavior_758018_2025-03-21_11-00-34',\n",
       " 'behavior_752014_2025-03-25_12-09-20',\n",
       " 'behavior_752014_2025-03-26_11-18-57',\n",
       " 'behavior_752014_2025-03-27_12-03-59',\n",
       " 'behavior_752014_2025-03-28_11-04-59',\n",
       " 'behavior_761038_2025-04-15_10-25-11',\n",
       " 'behavior_761038_2025-04-16_10-39-10',\n",
       " 'behavior_761038_2025-04-17_11-03-16',\n",
       " 'behavior_761038_2025-04-18_12-37-39',\n",
       " 'ecephys_763360_2025-04-15_12-16-29',\n",
       " 'ecephys_763360_2025-04-16_13-29-55',\n",
       " 'behavior_782394_2025-04-22_10-53-28',\n",
       " 'behavior_782394_2025-04-23_10-51-17',\n",
       " 'behavior_782394_2025-04-24_12-07-34',\n",
       " 'behavior_782394_2025-04-25_11-13-21',\n",
       " 'behavior_763590_2025-05-01_10-59-18',\n",
       " 'behavior_763590_2025-05-02_11-07-09',\n",
       " 'behavior_781166_2025-05-13_14-04-27',\n",
       " 'behavior_781166_2025-05-14_14-18-28',\n",
       " 'behavior_781166_2025-05-15_14-20-51',\n",
       " 'behavior_781166_2025-05-16_14-16-34',\n",
       " 'behavior_785956_2025-05-20_14-15-19',\n",
       " 'behavior_785956_2025-05-21_13-42-02',\n",
       " 'behavior_785956_2025-05-23_13-45-21',\n",
       " 'behavior_784806_2025-06-17_14-59-23',\n",
       " 'behavior_784806_2025-06-18_13-39-50',\n",
       " 'behavior_784806_2025-06-20_13-39-16',\n",
       " 'behavior_791691_2025-06-24_13-21-29',\n",
       " 'behavior_791691_2025-06-25_14-06-10',\n",
       " 'behavior_791691_2025-06-26_13-39-26',\n",
       " 'behavior_791691_2025-06-27_13-54-30',\n",
       " 'behavior_784803_2025-07-01_13-58-26',\n",
       " 'behavior_784803_2025-07-02_13-41-41',\n",
       " 'behavior_784803_2025-07-03']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unit_1</th>\n",
       "      <th>unit_2</th>\n",
       "      <th>cross_corr_long</th>\n",
       "      <th>cross_corr_short</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>([0.10200926919638711, 0.04362907474724333, 0....</td>\n",
       "      <td>([0.0036463771130829893, 0.008541877187731667,...</td>\n",
       "      <td>7.165321e+06</td>\n",
       "      <td>7.171568e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>12</td>\n",
       "      <td>([0.07899574598134228, 0.04555429368121589, 0....</td>\n",
       "      <td>([0.009465412686014389, 0.005973386332210205, ...</td>\n",
       "      <td>7.165321e+06</td>\n",
       "      <td>7.171568e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>15</td>\n",
       "      <td>([0.0527512776581984, 0.043061203472371384, 0....</td>\n",
       "      <td>([0.004471735748298048, 0.004735447002790088, ...</td>\n",
       "      <td>7.165321e+06</td>\n",
       "      <td>7.171568e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10</td>\n",
       "      <td>18</td>\n",
       "      <td>([0.017524276074430887, -0.011870131140818849,...</td>\n",
       "      <td>([0.005815145606901504, 0.003577636879219868, ...</td>\n",
       "      <td>7.165321e+06</td>\n",
       "      <td>7.171568e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>23</td>\n",
       "      <td>([0.04341201869179076, 0.041732545063786194, 0...</td>\n",
       "      <td>([0.004937083740363691, 0.001273885942614803, ...</td>\n",
       "      <td>7.165321e+06</td>\n",
       "      <td>7.171568e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10</td>\n",
       "      <td>24</td>\n",
       "      <td>([0.04589335236936446, 0.03281382579775501, 0....</td>\n",
       "      <td>([0.004746920685482899, 0.0033847179703455055,...</td>\n",
       "      <td>7.165321e+06</td>\n",
       "      <td>7.171568e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>10</td>\n",
       "      <td>25</td>\n",
       "      <td>([0.11744807261371962, 0.08945177046470547, 0....</td>\n",
       "      <td>([0.007906761137817098, 0.007292462947555057, ...</td>\n",
       "      <td>7.165321e+06</td>\n",
       "      <td>7.171568e+06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  unit_1 unit_2                                    cross_corr_long  \\\n",
       "0     10     11  ([0.10200926919638711, 0.04362907474724333, 0....   \n",
       "1     10     12  ([0.07899574598134228, 0.04555429368121589, 0....   \n",
       "2     10     15  ([0.0527512776581984, 0.043061203472371384, 0....   \n",
       "3     10     18  ([0.017524276074430887, -0.011870131140818849,...   \n",
       "4     10     23  ([0.04341201869179076, 0.041732545063786194, 0...   \n",
       "5     10     24  ([0.04589335236936446, 0.03281382579775501, 0....   \n",
       "6     10     25  ([0.11744807261371962, 0.08945177046470547, 0....   \n",
       "\n",
       "                                    cross_corr_short         start  \\\n",
       "0  ([0.0036463771130829893, 0.008541877187731667,...  7.165321e+06   \n",
       "1  ([0.009465412686014389, 0.005973386332210205, ...  7.165321e+06   \n",
       "2  ([0.004471735748298048, 0.004735447002790088, ...  7.165321e+06   \n",
       "3  ([0.005815145606901504, 0.003577636879219868, ...  7.165321e+06   \n",
       "4  ([0.004937083740363691, 0.001273885942614803, ...  7.165321e+06   \n",
       "5  ([0.004746920685482899, 0.0033847179703455055,...  7.165321e+06   \n",
       "6  ([0.007906761137817098, 0.007292462947555057, ...  7.165321e+06   \n",
       "\n",
       "            end  \n",
       "0  7.171568e+06  \n",
       "1  7.171568e+06  \n",
       "2  7.171568e+06  \n",
       "3  7.171568e+06  \n",
       "4  7.171568e+06  \n",
       "5  7.171568e+06  \n",
       "6  7.171568e+06  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_corr_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
