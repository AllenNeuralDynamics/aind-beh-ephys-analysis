{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import spikeinterface as si\n",
    "import spikeinterface.widgets as sw\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "import spikeinterface.postprocessing as spost\n",
    "import spikeinterface.qualitymetrics as sqm\n",
    "import spikeinterface.curation as scur\n",
    "\n",
    "# recompute qc\n",
    "from spikeinterface.qualitymetrics.misc_metrics import isi_violations, presence_ratio, amplitude_cutoff\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "import spikeinterface.comparison as sc\n",
    "import spikeinterface.widgets as sw\n",
    "\n",
    "import json\n",
    "\n",
    "from scipy.stats import pearsonr\n",
    "from scipy.stats import gaussian_kde\n",
    "import pandas as pd\n",
    "\n",
    "import spikeinterface as si\n",
    "import spikeinterface.preprocessing as spre\n",
    "import spikeinterface.postprocessing as spost\n",
    "import spikeinterface.exporters as sexp\n",
    "\n",
    "import numpy as np\n",
    "import shutil\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Input info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "session = 'behavior_717121_2024-06-15_10-00-58'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_dir = f'/root/capsule/data/{session}/ecephys/'\n",
    "if not os.path.exists(raw_dir):\n",
    "    raw_dir = f'/root/capsule/data/{session}/'\n",
    "stream_name = 'experiment1_Record Node 104#Neuropix-PXI-100.ProbeA_recording1'\n",
    "data_folder = '/root/capsule/data'\n",
    "for dir in os.listdir(data_folder):\n",
    "    if (session in dir) and (\"sorted\" in dir) and (\"curated\" in dir):\n",
    "        curated_sorting_dir = f'{data_folder}/{dir}'\n",
    "        break\n",
    "curated_folder = curated_sorting_dir + '/curated/' + stream_name\n",
    "postprocessed_folder = curated_sorting_dir + '/postprocessed/' + stream_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def qm_simple_sorting(sorting, timestamps, sample_rate=30000, bin_duration_s=60, mean_fr_ratio_thresh=0.01):\n",
    "    unit_ids = sorting.get_unit_ids()\n",
    "    isi_violations_ratio = [None]*len(unit_ids)\n",
    "    isi_violations_rate = [None]*len(unit_ids)\n",
    "    isi_violations_count = [None]*len(unit_ids)\n",
    "    presence_ratio_qc = [None]*len(unit_ids)\n",
    "    firing_rate = [None]*len(unit_ids) \n",
    "    recLength = timestamps[-1] - timestamps[0]\n",
    "    bin_edges = np.arange(timestamps[0], timestamps[-1], bin_duration_s)\n",
    "\n",
    "\n",
    "    for unitInd, unit_id in enumerate(unit_ids):\n",
    "        timestampsCurr = timestamps[sorting.get_unit_spike_train(unit_id)]\n",
    "        # isi_v\n",
    "        isi_violations_ratio[unitInd], isi_violations_rate[unitInd], isi_violations_count[unitInd] = isi_violations([timestampsCurr], recLength, isi_threshold_s=0.0015, min_isi_s=1/sample_rate)\n",
    "        # presence ratio\n",
    "        unit_fr = len(timestampsCurr)/recLength\n",
    "        bin_n_spikes_thres = np.floor(unit_fr * bin_duration_s * mean_fr_ratio_thresh)\n",
    "        presence_ratio_qc[unitInd] = presence_ratio(timestampsCurr, recLength, bin_edges=bin_edges, bin_n_spikes_thres=bin_n_spikes_thres)\n",
    "        # firing rate\n",
    "        firing_rate[unitInd] = unit_fr\n",
    "\n",
    "    qm = pd.DataFrame({\n",
    "                    'unit_id': unit_ids,\n",
    "                    'isi_violations_ratio': isi_violations_ratio,\n",
    "                    'presence_ratio': presence_ratio_qc,\n",
    "                    'firing_rate': firing_rate})\n",
    "    return qm       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_preprocess_recording(raw_data_folder, stream_name):\n",
    "    compressed_folder = raw_data_folder + \"/ecephys_compressed/\"\n",
    "    raw_stream_name = stream_name[:stream_name.find(\"_recording\")]\n",
    "    recording = si.read_zarr(compressed_folder+f\"{raw_stream_name}.zarr\")\n",
    "    # preprocess\n",
    "    recording_processed = spre.phase_shift(recording)\n",
    "    recording_processed = spre.highpass_filter(recording_processed)    \n",
    "    recording_processed = spre.common_reference(recording_processed)\n",
    "    return recording_processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_qm(sorting_dir):\n",
    "    qm_dir = sorting_dir + '/postprocessed'\n",
    "    for root, dirs, files in os.walk(qm_dir):\n",
    "        # Check if 'quality' folder is in the current directory\n",
    "        if 'quality_metrics' in dirs:\n",
    "            quality_folder_path = os.path.join(root, 'quality_metrics')\n",
    "            print(quality_folder_path)\n",
    "            break\n",
    "    \n",
    "    if 'quality_folder_path' in locals(): \n",
    "        qm_file = os.path.join(quality_folder_path, 'metrics.csv')\n",
    "        qm = pd.read_csv(qm_file, index_col=0)\n",
    "        return qm\n",
    "    else:\n",
    "        print('No quality metrics folder found.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load timestamps\n",
    "timestamps_file = Path(raw_dir + '/ecephys_clipped/Record Node 104/experiment1/recording1/continuous/Neuropix-PXI-100.ProbeA/timestamps.npy')\n",
    "if Path.exists(timestamps_file):\n",
    "    timestamps = np.load(timestamps_file)\n",
    "else:\n",
    "    timestamps_file = Path(raw_dir + '/ecephys/ecephys_clipped/Record Node 104/experiment1/recording1/continuous/Neuropix-PXI-100.ProbeA/timestamps.npy')\n",
    "    timestamps = np.load(timestamps_file)\n",
    "# load recording\n",
    "recording_processed = load_and_preprocess_recording(raw_dir, stream_name)\n",
    "# load sorting\n",
    "sorting = si.load_extractor(curated_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/root/capsule/data/behavior_717121_2024-06-15_10-00-58_sorted-curated_2024-07-25_06-45-59/postprocessed/experiment1_Record Node 104#Neuropix-PXI-100.ProbeA_recording1/quality_metrics\n"
     ]
    }
   ],
   "source": [
    "# load we\n",
    "we = si.load_waveforms(postprocessed_folder, with_recording=False)\n",
    "we.set_recording(recording_processed)\n",
    "# load qm\n",
    "qm = load_qm(curated_sorting_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sorting\n",
    "counts = np.array(list(sorting.count_num_spikes_per_unit().values()))\n",
    "unit_ids = sorting.unit_ids\n",
    "labels = sorting.get_property('decoder_label')\n",
    "\n",
    "# recalculate qm\n",
    "sample_rate = 30000\n",
    "bin_duration_s = 60.0\n",
    "mean_fr_ratio_thresh = 0.01\n",
    "qm_simple = qm_simple_sorting(sorting, timestamps)\n",
    "\n",
    "pass_qc = (qm['isi_violations_ratio']<0.1) & (qm['firing_rate']>0.2) & (qm['presence_ratio']>0.95)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Export and save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/sklearn/base.py:376: InconsistentVersionWarning: Trying to unpickle estimator IncrementalPCA from version 1.5.0 when using version 1.5.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "outfolder = '/root/capsule/scratch/features/' + session\n",
    "pc = we.load_extension(\"principal_components\")\n",
    "pc_sparsity = pc.get_sparsity()\n",
    "max_num_channels_pc = max(len(chan_inds) for chan_inds in pc_sparsity.unit_id_to_channel_indices.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a75b30f830e4ee381943a0370a3654c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "extract PCs:   0%|          | 0/6396 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# export pc features\n",
    "pc_file = outfolder + '/pc_feature.npy'\n",
    "os.mkdir(outfolder)\n",
    "pc.run_for_all_spikes(pc_file, n_jobs = 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export unit_ids and channel ids\n",
    "pc_feature_ind = -np.ones((len(unit_ids), max_num_channels_pc), dtype=\"int64\")\n",
    "for unit_ind, unit_id in enumerate(unit_ids):\n",
    "    chan_inds = pc_sparsity.unit_id_to_channel_indices[unit_id]\n",
    "    pc_feature_ind[unit_ind, : len(chan_inds)] = chan_inds\n",
    "np.save(outfolder + \"/pc_feature_ind.npy\", pc_feature_ind)\n",
    "# export cluster id and spike times\n",
    "all_spikes_seg0 = sorting.to_spike_vector(concatenated=False)[0]\n",
    "spike_times = all_spikes_seg0[\"sample_index\"]\n",
    "spike_labels = all_spikes_seg0[\"unit_index\"]\n",
    "spike_labels = unit_ids[spike_labels]\n",
    "np.save(outfolder + \"/spike_times.npy\", spike_times[:, np.newaxis])\n",
    "np.save(outfolder + \"/spike_templates.npy\", spike_labels[:, np.newaxis])\n",
    "np.save(outfolder + \"/spike_clusters.npy\", spike_labels[:, np.newaxis])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
