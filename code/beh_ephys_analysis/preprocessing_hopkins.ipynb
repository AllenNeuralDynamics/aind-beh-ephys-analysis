{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append('/root/capsule/code/beh_ephys_analysis')\n",
    "from utils.beh_functions import parseSessionID, session_dirs, plot_session_in_time_all, plot_session_glm\n",
    "from utils.hdf5_extractor import HDF5Recording\n",
    "from behavior_and_time_alignment import beh_and_time_alignment, transfer_nwb\n",
    "import shutil\n",
    "from aind_dynamic_foraging_data_utils.nwb_utils import load_nwb_from_filename\n",
    "import pandas as pd\n",
    "from joblib import Parallel, delayed\n",
    "from aind_dynamic_foraging_basic_analysis.plot.plot_foraging_session import plot_foraging_session, plot_foraging_session_nwb\n",
    "from aind_dynamic_foraging_basic_analysis.licks.lick_analysis import plot_lick_analysis\n",
    "import datetime\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "session_id = 'behavior_ZS061_2021-04-17_16-50-25'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Old data, using hopkins formats\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/root/capsule/scratch/ZS061/behavior_ZS061_2021-04-17_16-50-25/behavior/behavior_ZS061_2021-04-17_16-50-25.nwb'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session_dir = session_dirs(session_id)\n",
    "session_dir['nwb_beh']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def beh_and_time_alignment_hopkins(session, ephys_cut = [0, 0]):\n",
    "    session_dir = session_dirs(session)\n",
    "    print(session)\n",
    "    qm_dict = {'soundcard_sync': True, 'ephys_sync': None}\n",
    "    timestamp = datetime.datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "    output_file = os.path.join(session_dir['processed_dir'], f\"{session}_process_record.txt\")\n",
    "\n",
    "    # Redirect stdout to the file\n",
    "    if not os.path.exists(output_file):\n",
    "        log_file = open(output_file, \"w\") \n",
    "    else: \n",
    "        log_file = open(output_file, \"a\")\n",
    "    sys.stdout = log_file\n",
    "    print(f\"Session: {session} processed at {timestamp}\")\n",
    "\n",
    "\n",
    "    # %%\n",
    "    print(session)\n",
    "    aniID, date_time, string = parseSessionID(session)\n",
    "\n",
    "    # %%\n",
    "    nwb_file = session_dir['nwb_beh']\n",
    "    if not os.path.exists(nwb_file):\n",
    "        print('NWB file does not exist.')\n",
    "    else:\n",
    "        print('Plotting session.')\n",
    "        nwb = load_nwb_from_filename(nwb_file)\n",
    "        fig = plot_session_in_time_all(nwb)\n",
    "        fig.savefig(os.path.join(session_dir['beh_fig_dir'], session + '_choice_reward.pdf'))\n",
    "        # display(fig)\n",
    "        \n",
    "        fig, _ = plot_lick_analysis(nwb)\n",
    "        fig.savefig(os.path.join(session_dir['beh_fig_dir'], session + '_lick_analysis.pdf'))\n",
    "        # display(fig)\n",
    "\n",
    "        fig, _, _ = plot_session_glm(session, tMax=5)\n",
    "        fig.savefig(os.path.join(session_dir['beh_fig_dir'], session + '_glm.pdf'))\n",
    "        # display(fig)\n",
    "\n",
    "        # plt.close('all')\n",
    "    if os.path.exists(nwb_file):\n",
    "        # %%\n",
    "        left_licks = nwb.acquisition[\"left_lick_time\"].timestamps[:]\n",
    "        right_licks = nwb.acquisition[\"right_lick_time\"].timestamps[:]\n",
    "        all_licks = np.sort(np.concatenate((right_licks, left_licks)))\n",
    "        df_trial = nwb.trials.to_dataframe()\n",
    "        plt.figure()\n",
    "        plt.hist(all_licks, alpha=0.5, label='licks', density=True)\n",
    "        plt.hist(df_trial['goCue_start_time'], alpha=0.5, label='goCue', density=True)\n",
    "        plt.legend()\n",
    "        plt.savefig(os.path.join(session_dir['beh_fig_dir'], session + '_licks_vs_goCue.pdf'))\n",
    "        if np.abs(np.mean(all_licks) - np.mean(df_trial['goCue_start_time'])) > 0.2*(df_trial['goCue_start_time'].max() - df_trial['goCue_start_time'].min()):\n",
    "            print(f'{session} sound card is not synced.')\n",
    "            qm_dict['soundcard_sync'] = False\n",
    "        else:\n",
    "            print(f'{session} sound card is synced.')\n",
    "            qm_dict['soundcard_sync'] = True\n",
    "\n",
    "        # %% [markdown]\n",
    "        # ### Check ephys alignment\n",
    "\n",
    "        # example neurons\n",
    "        # extract from nwb\n",
    "        # nwb = load_nwb_from_filename(session_dir['nwb_dir_raw'])\n",
    "        # unit_spikes = nwb.units[::10]['spike_times']\n",
    "        # mean_spike_times = [np.mean(unit_spike) for unit_spike in unit_spikes]\n",
    "        # mean_spike_times = np.mean(np.array(mean_spike_times))\n",
    "        # extract from sorting\n",
    "        # recording = si.read_zarr(session_dir['raw_rec'])\n",
    "        # sorting.register_recording(recording)\n",
    "        # if recording exists, then check if ephys is synced with sound card\n",
    "        if os.path.exists(session_dir['raw_rec']):\n",
    "            recording = HDF5Recording(session_dir['raw_rec'])\n",
    "            timestamps = recording.get_times()\n",
    "            if load_nwb_from_filename(session_dir['nwb_dir_raw']).units is not None:\n",
    "                unit_spikes = load_nwb_from_filename(session_dir['nwb_dir_raw']).units[:]['spike_times']\n",
    "                mean_spike_times = [np.mean(unit_spike) for unit_spike in unit_spikes]\n",
    "                mean_spike_times = np.mean(np.array(mean_spike_times))\n",
    "            else:\n",
    "                mean_spike_times = np.mean(timestamps)\n",
    "            figure, ax = plt.subplots(1, 1, figsize=(10, 5))\n",
    "            ax.hist(timestamps, bins=100, density=True, alpha=0.5, label='ephys')\n",
    "            ax.hist(all_licks, bins=100, density=True, alpha=0.5, label='licks')\n",
    "            ax.hist(df_trial['goCue_start_time'], bins=100, density=True, alpha=0.5, label='goCue')\n",
    "            if load_nwb_from_filename(session_dir['nwb_dir_raw']).units is not None:\n",
    "                for i, unit_spike in enumerate(unit_spikes):\n",
    "                    ax.hist(unit_spike, bins=100, density=True, alpha=0.2, color='k')\n",
    "                ax.legend()\n",
    "            figure.savefig(os.path.join(session_dir['alignment_dir'], 'lick_goCue_ephys_time.pdf'))\n",
    "            if np.abs(np.mean(all_licks) - np.mean(timestamps)) < 0.2*(timestamps[-1]-timestamps[0]) and np.abs(np.mean(timestamps) - mean_spike_times) < 0.2*(timestamps[-1]-timestamps[0]): \n",
    "                print(f'{session} ephys is synced.')\n",
    "                qm_dict['ephys_sync'] = True\n",
    "            else:\n",
    "                print(f'{session} ephys is not synced.')\n",
    "                qm_dict['ephys_sync'] = False\n",
    "            # %% find a stable time period\n",
    "            ephys_cut_new = [timestamps[0]+ephys_cut[0], timestamps[-1]-ephys_cut[1]]\n",
    "            qm_dict['ephys_cut'] = ephys_cut_new\n",
    "        else:\n",
    "            print(f'{session} ephys recording does not exist.')\n",
    "            qm_dict['ephys_sync'] = None\n",
    "            qm_dict['ephys_cut'] = None\n",
    "    else: \n",
    "        qm_dict['ephys_sync'] = None\n",
    "        qm_dict['ephys_cut'] = None\n",
    "        qm_dict['soundcard_sync'] = None\n",
    "\n",
    "    # %%\n",
    "    qm_file = os.path.join(session_dir['processed_dir'], f\"{session}_qm.json\")\n",
    "    with open(qm_file, 'w') as f:\n",
    "        json.dump(qm_dict, f, indent=4)\n",
    "    print(f\"Output saved to {output_file}\")\n",
    "    sys.stdout = sys.__stdout__\n",
    "    # Close the file\n",
    "    log_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/aind_dynamic_foraging_basic_analysis/licks/lick_analysis.py:39: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`). Consider using `matplotlib.pyplot.close()`.\n",
      "  fig = plt.figure(figsize=(15, 8))\n"
     ]
    }
   ],
   "source": [
    "beh_and_time_alignment_hopkins('behavior_ZS059_2021-04-05_14-33-48')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "session_df = pd.read_csv('/root/capsule/code/data_management/hopkins_session_assets.csv')\n",
    "session_ids = session_df['session_id'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process(session_id):\n",
    "    session_dir = session_dirs(session_id);\n",
    "    if os.path.exists(session_dir['nwb_dir_raw']):\n",
    "        try:\n",
    "            # transfer_nwb(session_id);\n",
    "            beh_and_time_alignment_hopkins(session_id, ephys_cut=[0, 0])\n",
    "            print(f'Processed {session_id}')\n",
    "            plt.close('all')\n",
    "        except:\n",
    "            print(f'{session_id} failed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/numpy/_core/fromnumeric.py:3904: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/opt/conda/lib/python3.10/site-packages/numpy/_core/_methods.py:147: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/opt/conda/lib/python3.10/site-packages/numpy/lib/_histograms_impl.py:902: RuntimeWarning: invalid value encountered in divide\n",
      "  return n/db/n.sum(), bin_edges\n",
      "/root/capsule/code/beh_ephys_analysis/utils/beh_functions.py:1175: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`). Consider using `matplotlib.pyplot.close()`.\n",
      "  fig, _ = plt.subplots(figsize=(12, 6))\n"
     ]
    }
   ],
   "source": [
    "# Parallel(n_jobs=5)(delayed(process)(session, data_type) for session in session_list[82:94])\n",
    "Parallel(n_jobs=-1)(delayed(process)(session_id) for session_id in session_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Old data, using hopkins formats\n"
     ]
    }
   ],
   "source": [
    "transfer_nwb(session_id) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
