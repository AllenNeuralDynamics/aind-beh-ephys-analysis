{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append('/root/capsule/code/beh_ephys_analysis')\n",
    "from harp.clock import decode_harp_clock, align_timestamps_to_anchor_points\n",
    "from open_ephys.analysis import Session\n",
    "import datetime\n",
    "from aind_ephys_rig_qc.temporal_alignment import search_harp_line\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "import pandas as pd\n",
    "from pynwb import NWBFile, TimeSeries, NWBHDF5IO\n",
    "from scipy.io import loadmat\n",
    "from scipy.stats import zscore\n",
    "import ast\n",
    "from utils.plot_utils import combine_pdf_big\n",
    "\n",
    "from open_ephys.analysis import Session\n",
    "from pathlib import Path\n",
    "import glob\n",
    "\n",
    "import json\n",
    "import seaborn as sns\n",
    "from PyPDF2 import PdfMerger\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import statsmodels.api as sm\n",
    "import re\n",
    "from aind_dynamic_foraging_basic_analysis.plot.plot_foraging_session import plot_foraging_session\n",
    "from aind_dynamic_foraging_data_utils.nwb_utils import load_nwb_from_filename\n",
    "from hdmf_zarr.nwb import NWBZarrIO\n",
    "from utils.beh_functions import session_dirs, parseSessionID, load_model_dv, makeSessionDF, get_session_tbl, get_unit_tbl, get_history_from_nwb\n",
    "from utils.ephys_functions import*\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import scipy.stats as stats\n",
    "from joblib import Parallel, delayed\n",
    "from multiprocessing import Pool\n",
    "from functools import partial\n",
    "import time\n",
    "import spikeinterface as si\n",
    "import shutil\n",
    "import seaborn as sns\n",
    "import math\n",
    "import seaborn as sns\n",
    "from sklearn.decomposition import PCA\n",
    "from scipy.stats import zscore\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make combined session-unit table\n",
    "df = pd.read_csv('/root/capsule/code/data_management/session_assets.csv')\n",
    "session_ids = df['session_id'].values\n",
    "behs = df['behavior'].values\n",
    "exclude = ['ecephys_717120_2024-03-06_12-23-53', 'ecephys_713854_2024-03-08_14-54-25', 'ecephys_713854_2024-03-08_16-20-33', 'behavior_754897_2025-03-15_11-32-18', 'behavior_752014_2025-03-28_11-04-59']\n",
    "session_ids, behs = zip(*[\n",
    "    (session, beh)\n",
    "    for session, beh in zip(session_ids, behs)\n",
    "    if isinstance(session, str) and session not in exclude\n",
    "])\n",
    "session_ids = list(session_ids)\n",
    "behs = list(behs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing ecephys_713854_2024-03-05_12-01-40\n",
      "Processing ecephys_713854_2024-03-05_13-01-09\n",
      "Processing ecephys_713854_2024-03-05_13-31-20\n",
      "Processing ecephys_717120_2024-03-06_12-54-27\n",
      "Processing ecephys_717120_2024-03-07_12-12-02\n",
      "Processing ecephys_713854_2024-03-08_15-43-01\n",
      "There is no nwb file in the curated directory.\n",
      "Processing ecephys_684930_2023-09-27_10-04-04\n",
      "Processing ecephys_684930_2023-09-28_11-45-27\n",
      "Processing ecephys_684930_2023-09-28_12-44-15\n",
      "Processing ecephys_687697_2023-09-15_11-30-06\n",
      "Processing ecephys_687697_2023-09-15_12-36-06\n",
      "Processing ecephys_691893_2023-10-05_12-46-57\n",
      "Processing ecephys_691893_2023-10-06_13-48-18\n",
      "Processing behavior_716325_2024-05-31_10-31-14\n",
      "Processing behavior_717121_2024-06-15_10-00-58\n",
      "There are multiple recordings in the raw nwb directory. Please specify the recording you would like to use.\n",
      "Processing behavior_751004_2024-12-19_11-50-37\n",
      "Processing behavior_751004_2024-12-20_13-26-11\n",
      "Processing behavior_751004_2024-12-21_13-28-28\n",
      "Processing behavior_751004_2024-12-22_13-09-17\n",
      "Processing behavior_751004_2024-12-23_14-20-03\n",
      "Processing behavior_751769_2025-01-16_11-32-05\n",
      "Processing behavior_751769_2025-01-17_11-37-39\n",
      "Processing behavior_751769_2025-01-18_10-15-25\n",
      "Processing behavior_758017_2025-02-04_11-57-38\n",
      "Processing behavior_758017_2025-02-05_11-42-34\n",
      "behavior_758017_2025-02-06_11-26-14\n",
      "Processing behavior_758017_2025-02-06_11-26-14\n",
      "Processing behavior_758017_2025-02-07_14-11-08\n",
      "Processing behavior_751766_2025-02-11_11-53-38\n",
      "Processing behavior_751766_2025-02-13_11-31-21\n",
      "Processing behavior_751766_2025-02-14_11-37-11\n",
      "There is no nwb file in the raw directory.\n",
      "Processing behavior_751181_2025-02-25_12-12-35\n",
      "Processing behavior_751181_2025-02-26_11-51-19\n",
      "Processing behavior_751181_2025-02-27_11-24-47\n",
      "Processing behavior_754897_2025-03-11_12-07-41\n",
      "Processing behavior_754897_2025-03-12_12-23-15\n",
      "Processing behavior_754897_2025-03-13_11-20-42\n",
      "Processing behavior_754897_2025-03-14_11-28-53\n",
      "Processing behavior_758018_2025-03-19_11-16-44\n",
      "Processing behavior_758018_2025-03-20_11-53-05\n",
      "Processing behavior_758018_2025-03-21_11-00-34\n",
      "Processing behavior_752014_2025-03-25_12-09-20\n",
      "Processing behavior_752014_2025-03-26_11-18-57\n",
      "Processing behavior_752014_2025-03-27_12-03-59\n",
      "Processing behavior_761038_2025-04-15_10-25-11\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/root/capsule/code/beh_ephys_analysis/session_combine/count_neurons_summary.ipynb Cell 3\u001b[0m line \u001b[0;36m8\n\u001b[1;32m     <a href='vscode-notebook-cell://codeocean.allenneuraldynamics.org/root/capsule/code/beh_ephys_analysis/session_combine/count_neurons_summary.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=82'>83</a>\u001b[0m     wf_opt_aligned \u001b[39m=\u001b[39m [unit_tbl[\u001b[39m'\u001b[39m\u001b[39mpeak_wf_aligned\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mvalues]\n\u001b[1;32m     <a href='vscode-notebook-cell://codeocean.allenneuraldynamics.org/root/capsule/code/beh_ephys_analysis/session_combine/count_neurons_summary.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=83'>84</a>\u001b[0m     wf_opt_2d \u001b[39m=\u001b[39m [unit_tbl[\u001b[39m'\u001b[39m\u001b[39mwf_2d\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mvalues]\n\u001b[0;32m---> <a href='vscode-notebook-cell://codeocean.allenneuraldynamics.org/root/capsule/code/beh_ephys_analysis/session_combine/count_neurons_summary.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=88'>89</a>\u001b[0m amp_opt \u001b[39m=\u001b[39m [\n\u001b[1;32m     <a href='vscode-notebook-cell://codeocean.allenneuraldynamics.org/root/capsule/code/beh_ephys_analysis/session_combine/count_neurons_summary.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=89'>90</a>\u001b[0m                 np\u001b[39m.\u001b[39mmax(wf_opt_curr) \u001b[39m-\u001b[39m np\u001b[39m.\u001b[39mmin(wf_opt_curr) \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(wf_opt_curr, np\u001b[39m.\u001b[39mndarray) \u001b[39melse\u001b[39;00m curr_amp_unit\n\u001b[1;32m     <a href='vscode-notebook-cell://codeocean.allenneuraldynamics.org/root/capsule/code/beh_ephys_analysis/session_combine/count_neurons_summary.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=90'>91</a>\u001b[0m                 \u001b[39mfor\u001b[39;00m wf_opt_curr, curr_amp_unit \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(wf_opt, amp)\n\u001b[1;32m     <a href='vscode-notebook-cell://codeocean.allenneuraldynamics.org/root/capsule/code/beh_ephys_analysis/session_combine/count_neurons_summary.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=91'>92</a>\u001b[0m             ]   \u001b[39m# amplitude of optimized waveforms\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://codeocean.allenneuraldynamics.org/root/capsule/code/beh_ephys_analysis/session_combine/count_neurons_summary.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=92'>93</a>\u001b[0m peak_opt \u001b[39m=\u001b[39m [\n\u001b[1;32m     <a href='vscode-notebook-cell://codeocean.allenneuraldynamics.org/root/capsule/code/beh_ephys_analysis/session_combine/count_neurons_summary.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=93'>94</a>\u001b[0m                 curr_peak_opt_unit \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m np\u001b[39m.\u001b[39misnan(curr_peak_opt_unit) \u001b[39melse\u001b[39;00m curr_peak_unit\n\u001b[1;32m     <a href='vscode-notebook-cell://codeocean.allenneuraldynamics.org/root/capsule/code/beh_ephys_analysis/session_combine/count_neurons_summary.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=94'>95</a>\u001b[0m                 \u001b[39mfor\u001b[39;00m curr_peak_opt_unit, curr_peak_unit \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(\u001b[39mlist\u001b[39m(unit_tbl[\u001b[39m'\u001b[39m\u001b[39mamplitude_opt\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mvalues), \u001b[39mlist\u001b[39m(peaks))\n\u001b[1;32m     <a href='vscode-notebook-cell://codeocean.allenneuraldynamics.org/root/capsule/code/beh_ephys_analysis/session_combine/count_neurons_summary.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=95'>96</a>\u001b[0m             ]\n\u001b[1;32m     <a href='vscode-notebook-cell://codeocean.allenneuraldynamics.org/root/capsule/code/beh_ephys_analysis/session_combine/count_neurons_summary.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=97'>98</a>\u001b[0m all_amp\u001b[39m.\u001b[39mextend(amp_opt)  \u001b[39m# amplitude of max p response\u001b[39;00m\n",
      "\u001b[1;32m/root/capsule/code/beh_ephys_analysis/session_combine/count_neurons_summary.ipynb Cell 3\u001b[0m line \u001b[0;36m9\n\u001b[1;32m     <a href='vscode-notebook-cell://codeocean.allenneuraldynamics.org/root/capsule/code/beh_ephys_analysis/session_combine/count_neurons_summary.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=82'>83</a>\u001b[0m     wf_opt_aligned \u001b[39m=\u001b[39m [unit_tbl[\u001b[39m'\u001b[39m\u001b[39mpeak_wf_aligned\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mvalues]\n\u001b[1;32m     <a href='vscode-notebook-cell://codeocean.allenneuraldynamics.org/root/capsule/code/beh_ephys_analysis/session_combine/count_neurons_summary.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=83'>84</a>\u001b[0m     wf_opt_2d \u001b[39m=\u001b[39m [unit_tbl[\u001b[39m'\u001b[39m\u001b[39mwf_2d\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mvalues]\n\u001b[1;32m     <a href='vscode-notebook-cell://codeocean.allenneuraldynamics.org/root/capsule/code/beh_ephys_analysis/session_combine/count_neurons_summary.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=88'>89</a>\u001b[0m amp_opt \u001b[39m=\u001b[39m [\n\u001b[0;32m---> <a href='vscode-notebook-cell://codeocean.allenneuraldynamics.org/root/capsule/code/beh_ephys_analysis/session_combine/count_neurons_summary.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=89'>90</a>\u001b[0m                 np\u001b[39m.\u001b[39;49mmax(wf_opt_curr) \u001b[39m-\u001b[39m np\u001b[39m.\u001b[39mmin(wf_opt_curr) \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(wf_opt_curr, np\u001b[39m.\u001b[39mndarray) \u001b[39melse\u001b[39;00m curr_amp_unit\n\u001b[1;32m     <a href='vscode-notebook-cell://codeocean.allenneuraldynamics.org/root/capsule/code/beh_ephys_analysis/session_combine/count_neurons_summary.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=90'>91</a>\u001b[0m                 \u001b[39mfor\u001b[39;00m wf_opt_curr, curr_amp_unit \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(wf_opt, amp)\n\u001b[1;32m     <a href='vscode-notebook-cell://codeocean.allenneuraldynamics.org/root/capsule/code/beh_ephys_analysis/session_combine/count_neurons_summary.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=91'>92</a>\u001b[0m             ]   \u001b[39m# amplitude of optimized waveforms\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://codeocean.allenneuraldynamics.org/root/capsule/code/beh_ephys_analysis/session_combine/count_neurons_summary.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=92'>93</a>\u001b[0m peak_opt \u001b[39m=\u001b[39m [\n\u001b[1;32m     <a href='vscode-notebook-cell://codeocean.allenneuraldynamics.org/root/capsule/code/beh_ephys_analysis/session_combine/count_neurons_summary.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=93'>94</a>\u001b[0m                 curr_peak_opt_unit \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m np\u001b[39m.\u001b[39misnan(curr_peak_opt_unit) \u001b[39melse\u001b[39;00m curr_peak_unit\n\u001b[1;32m     <a href='vscode-notebook-cell://codeocean.allenneuraldynamics.org/root/capsule/code/beh_ephys_analysis/session_combine/count_neurons_summary.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=94'>95</a>\u001b[0m                 \u001b[39mfor\u001b[39;00m curr_peak_opt_unit, curr_peak_unit \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(\u001b[39mlist\u001b[39m(unit_tbl[\u001b[39m'\u001b[39m\u001b[39mamplitude_opt\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mvalues), \u001b[39mlist\u001b[39m(peaks))\n\u001b[1;32m     <a href='vscode-notebook-cell://codeocean.allenneuraldynamics.org/root/capsule/code/beh_ephys_analysis/session_combine/count_neurons_summary.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=95'>96</a>\u001b[0m             ]\n\u001b[1;32m     <a href='vscode-notebook-cell://codeocean.allenneuraldynamics.org/root/capsule/code/beh_ephys_analysis/session_combine/count_neurons_summary.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=97'>98</a>\u001b[0m all_amp\u001b[39m.\u001b[39mextend(amp_opt)  \u001b[39m# amplitude of max p response\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/numpy/_core/fromnumeric.py:3199\u001b[0m, in \u001b[0;36mmax\u001b[0;34m(a, axis, out, keepdims, initial, where)\u001b[0m\n\u001b[1;32m   3080\u001b[0m \u001b[39m@array_function_dispatch\u001b[39m(_max_dispatcher)\n\u001b[1;32m   3081\u001b[0m \u001b[39m@set_module\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mnumpy\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m   3082\u001b[0m \u001b[39mdef\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mmax\u001b[39m(a, axis\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, out\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, keepdims\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39m_NoValue, initial\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39m_NoValue,\n\u001b[1;32m   3083\u001b[0m          where\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39m_NoValue):\n\u001b[1;32m   3084\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   3085\u001b[0m \u001b[39m    Return the maximum of an array or maximum along an axis.\u001b[39;00m\n\u001b[1;32m   3086\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3197\u001b[0m \u001b[39m    5\u001b[39;00m\n\u001b[1;32m   3198\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 3199\u001b[0m     \u001b[39mreturn\u001b[39;00m _wrapreduction(a, np\u001b[39m.\u001b[39;49mmaximum, \u001b[39m'\u001b[39;49m\u001b[39mmax\u001b[39;49m\u001b[39m'\u001b[39;49m, axis, \u001b[39mNone\u001b[39;49;00m, out,\n\u001b[1;32m   3200\u001b[0m                           keepdims\u001b[39m=\u001b[39;49mkeepdims, initial\u001b[39m=\u001b[39;49minitial, where\u001b[39m=\u001b[39;49mwhere)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/numpy/_core/fromnumeric.py:86\u001b[0m, in \u001b[0;36m_wrapreduction\u001b[0;34m(obj, ufunc, method, axis, dtype, out, **kwargs)\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     84\u001b[0m             \u001b[39mreturn\u001b[39;00m reduction(axis\u001b[39m=\u001b[39maxis, out\u001b[39m=\u001b[39mout, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mpasskwargs)\n\u001b[0;32m---> 86\u001b[0m \u001b[39mreturn\u001b[39;00m ufunc\u001b[39m.\u001b[39;49mreduce(obj, axis, dtype, out, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mpasskwargs)\n",
      "\u001b[0;31mValueError\u001b[0m: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()"
     ]
    }
   ],
   "source": [
    "# loop through all sessions\n",
    "# count number of units pass qc and opto qc\n",
    "# check if exist in longer than 100 sessions \n",
    "# check if exist in pre/post stimulation\n",
    "# check if exist in anti-dromic stimulation\n",
    "all_sessions = []\n",
    "all_units = []\n",
    "all_qc_pass_units = [] # default qc pass\n",
    "all_real_units = [] # not noise, not artifact\n",
    "all_tagged_units = []\n",
    "in_behavior = []\n",
    "trial_count = []\n",
    "opto_tagging_pre = []\n",
    "opto_tagging_post = []\n",
    "anti = []\n",
    "probes = []\n",
    "all_p_max = []\n",
    "all_lat_max_p = []  # latency of max p response\n",
    "isi_v = []\n",
    "all_eu = []\n",
    "all_corr = []\n",
    "all_amp = []\n",
    "all_peak = []\n",
    "all_wf = []\n",
    "all_wf_aligned = []\n",
    "all_wf_2d = []\n",
    "y_loc = []\n",
    "in_df = []\n",
    "rec_side = []\n",
    "top = []\n",
    "bottom = []\n",
    "snr = []\n",
    "\n",
    "# p_resp_thresh = 0.5\n",
    "# lat_resp_thresh = 0.02\n",
    "\n",
    "target = 'soma'\n",
    "for session, beh in zip(session_ids, behs):\n",
    "    session_dir = session_dirs(session)\n",
    "    if session_dir['curated_dir_curated'] is not None:\n",
    "        if 'behavior_758017_2025-02-06_11-26-14' in session:\n",
    "            print('behavior_758017_2025-02-06_11-26-14')\n",
    "        print(f'Processing {session}')\n",
    "        data_type = 'curated'\n",
    "        # if session_dir['curated_dir_curated'] is not None:\n",
    "        #     data_type = 'curated'\n",
    "        # elif session_dir['curated_dir_raw'] is not None:\n",
    "        #     data_type = 'raw'\n",
    "        # else:\n",
    "        #     continue\n",
    "\n",
    "        unit_tbl = get_unit_tbl(session, data_type)\n",
    "        all_units.extend(unit_tbl['unit_id'].tolist())\n",
    "        all_qc_pass_units.extend(unit_tbl['default_qc'].tolist())  # default qc pass\n",
    "        # all_real_units.extend(unit_tbl['real_unit'].tolist())\n",
    "        all_tagged_units.extend(unit_tbl['tagged_loc'].tolist())  # tagged location (e.g. 'soma', 'axon', 'unspecified')\n",
    "        all_sessions.extend([session]*len(unit_tbl))\n",
    "        if 'p_max' not in unit_tbl.columns:\n",
    "            all_p_max.extend(unit_tbl['p_max_x'].tolist())\n",
    "            all_lat_max_p.extend(unit_tbl['lat_max_p_x'].tolist())\n",
    "            all_eu.extend(unit_tbl['euc_max_p_x'].tolist())\n",
    "            all_corr.extend(unit_tbl['corr_max_p_x'].tolist())\n",
    "            peaks = unit_tbl['peak_x'].values\n",
    "            amp = unit_tbl['amp_x'].values\n",
    "        else: \n",
    "            all_p_max.extend(unit_tbl['p_max'].tolist())  \n",
    "            all_lat_max_p.extend(unit_tbl['lat_max_p'].tolist()) \n",
    "            all_eu.extend(unit_tbl['euc_max_p'].tolist())\n",
    "            all_corr.extend(unit_tbl['corr_max_p'].tolist()) \n",
    "            peaks = unit_tbl['peak'].values\n",
    "            amp = unit_tbl['amp'].values\n",
    "     \n",
    "        isi_v.extend(unit_tbl['isi_violations_ratio'].tolist())  # ISI violations\n",
    "        snr.extend(unit_tbl['snr'].tolist())  # signal-to-noise ratio\n",
    "        y_loc.extend(unit_tbl['y_loc'].tolist())  # y location of the unit\n",
    "\n",
    "        if 'peak_wf_opt' in unit_tbl.columns:\n",
    "            wf_opt = [wf_opt_unit if isinstance(wf_opt_unit, np.ndarray) else wf_unit for wf_opt_unit, wf_unit in zip(unit_tbl['peak_wf_opt'], unit_tbl['peak_wf'])]  # peak waveform\n",
    "            wf_opt_aligned = [wf_opt_unit if isinstance(wf_opt_unit, np.ndarray) else wf_unit for wf_opt_unit, wf_unit in zip(unit_tbl['peak_wf_opt_aligned'], unit_tbl['peak_wf_aligned'])]  # peak waveform aligned\n",
    "            wf_opt_2d = [wf_opt_unit if isinstance(wf_opt_unit, np.ndarray) else wf_unit for wf_opt_unit, wf_unit in zip(unit_tbl['mat_wf_opt'], unit_tbl['wf_2d'])]  # peak waveform 2D\n",
    "        else:\n",
    "            wf_opt = [unit_tbl['peak_wf'].values]\n",
    "            wf_opt_aligned = [unit_tbl['peak_wf_aligned'].values]\n",
    "            wf_opt_2d = [unit_tbl['wf_2d'].values]\n",
    "\n",
    "        amp_opt = [\n",
    "                        np.max(wf_opt_curr) - np.min(wf_opt_curr) if isinstance(wf_opt_curr, np.ndarray) else curr_amp_unit\n",
    "                        for wf_opt_curr, curr_amp_unit in zip(wf_opt, amp)\n",
    "                    ]   # amplitude of optimized waveforms\n",
    "        peak_opt = [\n",
    "                        curr_peak_opt_unit if not np.isnan(curr_peak_opt_unit) else curr_peak_unit\n",
    "                        for curr_peak_opt_unit, curr_peak_unit in zip(list(unit_tbl['amplitude_opt'].values), list(peaks))\n",
    "                    ]\n",
    "        \n",
    "        all_amp.extend(amp_opt)  # amplitude of max p response\n",
    "        all_peak.extend(peak_opt)  # peak opto response\n",
    "        all_wf.extend(wf_opt)  # waveform of max p response\n",
    "        all_wf_aligned.extend(wf_opt_aligned)  # waveform of max p response\n",
    "        all_wf_2d.extend(wf_opt_2d)  # waveform of max p response\n",
    "        top.extend(unit_tbl['LC_range_top'].tolist())\n",
    "        bottom.extend(unit_tbl['LC_range_bottom'].tolist())\n",
    "\n",
    "        # session and opto information\n",
    "        session_df = get_session_tbl(session)\n",
    "        with open(os.path.join(session_dir[f'opto_dir_{data_type}'], f'{session}_opto_info_{target}.json')) as f:\n",
    "            opto_info = json.load(f)\n",
    "        opto_df = pd.read_csv(os.path.join(session_dir[f'opto_dir_{data_type}'], f'{session}_opto_session_{target}.csv'))\n",
    "        if len(opto_df[opto_df['pre_post'] == 'pre'])>0:\n",
    "            pre_end = np.max(opto_df[opto_df['pre_post'] == 'pre']['time'].values)\n",
    "        else:\n",
    "            pre_end = np.nan\n",
    "        \n",
    "        if len(opto_df[opto_df['pre_post'] == 'post'])>0:\n",
    "            post_start = np.min(opto_df[opto_df['pre_post'] == 'post']['time'].values)\n",
    "            post_end = np.max(opto_df[opto_df['pre_post'] == 'post']['time'].values)\n",
    "        else:\n",
    "            post_start = np.nan\n",
    "            post_end = np.nan\n",
    "            \n",
    "        for unit_id in unit_tbl['unit_id'].values:\n",
    "            curr_pre_opto = True\n",
    "            curr_post_opto = True \n",
    "            curr_anti_opto = True  \n",
    "            if session_df is not None:\n",
    "                curr_in_beh = True\n",
    "            else:\n",
    "                curr_in_beh = False\n",
    "                curr_trial_count = 0\n",
    "            unit = unit_tbl[unit_tbl['unit_id'] == unit_id]\n",
    "            unit_drift = load_drift(session, unit_id, data_type=data_type)\n",
    "            if session_df is not None:\n",
    "                go_cue_times = session_df['goCue_start_time']\n",
    "                if unit_drift is not None:\n",
    "                    if unit_drift['ephys_cut'][0] is not None:\n",
    "                        if unit_drift['ephys_cut'][0] > pre_end - 2*60:\n",
    "                            curr_pre_opto = False \n",
    "                        go_cue_times = go_cue_times[go_cue_times >= unit_drift['ephys_cut'][0]]         \n",
    "                    if unit_drift['ephys_cut'][1] is not None:\n",
    "                        if unit_drift['ephys_cut'][1] < post_start + 2*60:\n",
    "                            curr_post_opto = False\n",
    "                        if unit_drift['ephys_cut'][1] < post_end + 2*60:\n",
    "                            curr_anti_opto = False\n",
    "                        go_cue_times = go_cue_times[go_cue_times <= unit_drift['ephys_cut'][1]]\n",
    "                if len(go_cue_times) < 100: \n",
    "                    curr_in_beh = False\n",
    "                curr_trial_count = len(go_cue_times)\n",
    "            opto_tagging_pre.append(curr_pre_opto)\n",
    "            opto_tagging_post.append(curr_post_opto)\n",
    "            anti.append(curr_anti_opto)\n",
    "            trial_count.append(curr_trial_count)\n",
    "            in_behavior.append(curr_in_beh)\n",
    "        probes.extend([df[df['session_id']==session]['probe'].values[0]] * len(unit_tbl))\n",
    "        rec_side.extend([df[df['session_id']==session]['side'].values[0]]*len(unit_tbl))  # recording side\n",
    "        in_df.extend([beh] * len(unit_tbl))  # store session df for each unit\n",
    "combined_tagged_units = pd.DataFrame({'session': all_sessions,\n",
    "                                        'unit': all_units,\n",
    "                                        'qc_pass': all_qc_pass_units,\n",
    "                                        'opto_tagged': all_tagged_units,\n",
    "                                        'opto_tagging_pre': opto_tagging_pre,\n",
    "                                        'opto_tagging_post': opto_tagging_post,\n",
    "                                        'anti': anti,\n",
    "                                        'in_df': in_behavior,\n",
    "                                        'trial_count': trial_count,\n",
    "                                        'p_max': all_p_max,\n",
    "                                        'lat_max_p': all_lat_max_p,\n",
    "                                        'isi_violations': isi_v,\n",
    "                                        'snr': snr,\n",
    "                                        'eu': all_eu,\n",
    "                                        'corr': all_corr,\n",
    "                                        'amp': all_amp,\n",
    "                                        'peak': all_peak,\n",
    "                                        'wf': all_wf,\n",
    "                                        'wf_aligned': all_wf_aligned,\n",
    "                                        'wf_2d': all_wf_2d,\n",
    "                                        'probe': probes,\n",
    "                                        'y_loc': y_loc, \n",
    "                                        'rec_side': rec_side,\n",
    "                                        'top': top,\n",
    "                                        'bottom': bottom,\n",
    "                                        })\n",
    "\n",
    "# save dataframe in combined folder\n",
    "with open(os.path.join('/root/capsule/scratch/combined/combine_unit_tbl', 'combined_unit_tbl.pkl'), 'wb') as f:\n",
    "    pickle.dump(combined_tagged_units, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing ecephys_713854_2024-03-05_12-01-40\n",
      "Processing ecephys_713854_2024-03-05_13-01-09\n",
      "Processing ecephys_713854_2024-03-05_13-31-20\n",
      "Processing ecephys_717120_2024-03-06_12-54-27\n",
      "Processing ecephys_717120_2024-03-07_12-12-02\n",
      "Processing ecephys_713854_2024-03-08_15-43-01\n",
      "There is no nwb file in the curated directory.\n",
      "Processing ecephys_684930_2023-09-27_10-04-04\n",
      "Processing ecephys_684930_2023-09-28_11-45-27\n",
      "Processing ecephys_684930_2023-09-28_12-44-15\n",
      "Processing ecephys_687697_2023-09-15_11-30-06\n",
      "Processing ecephys_687697_2023-09-15_12-36-06\n",
      "Processing ecephys_691893_2023-10-05_12-46-57\n",
      "Processing ecephys_691893_2023-10-06_13-48-18\n",
      "Processing behavior_716325_2024-05-31_10-31-14\n",
      "Processing behavior_717121_2024-06-15_10-00-58\n",
      "There are multiple recordings in the raw nwb directory. Please specify the recording you would like to use.\n",
      "Processing behavior_751004_2024-12-19_11-50-37\n",
      "Processing behavior_751004_2024-12-20_13-26-11\n",
      "Processing behavior_751004_2024-12-21_13-28-28\n",
      "Processing behavior_751004_2024-12-22_13-09-17\n",
      "Processing behavior_751004_2024-12-23_14-20-03\n",
      "Processing behavior_751769_2025-01-16_11-32-05\n",
      "Processing behavior_751769_2025-01-17_11-37-39\n",
      "Processing behavior_751769_2025-01-18_10-15-25\n",
      "Processing behavior_758017_2025-02-04_11-57-38\n",
      "Processing behavior_758017_2025-02-05_11-42-34\n",
      "behavior_758017_2025-02-06_11-26-14\n",
      "Processing behavior_758017_2025-02-06_11-26-14\n",
      "Processing behavior_758017_2025-02-07_14-11-08\n",
      "Processing behavior_751766_2025-02-11_11-53-38\n",
      "Processing behavior_751766_2025-02-13_11-31-21\n",
      "Processing behavior_751766_2025-02-14_11-37-11\n",
      "There is no nwb file in the raw directory.\n",
      "Processing behavior_751181_2025-02-25_12-12-35\n",
      "Processing behavior_751181_2025-02-26_11-51-19\n",
      "Processing behavior_751181_2025-02-27_11-24-47\n",
      "Processing behavior_754897_2025-03-11_12-07-41\n",
      "Processing behavior_754897_2025-03-12_12-23-15\n",
      "Processing behavior_754897_2025-03-13_11-20-42\n",
      "Processing behavior_754897_2025-03-14_11-28-53\n",
      "Processing behavior_758018_2025-03-19_11-16-44\n",
      "Processing behavior_758018_2025-03-20_11-53-05\n",
      "Processing behavior_758018_2025-03-21_11-00-34\n",
      "Processing behavior_752014_2025-03-25_12-09-20\n",
      "Processing behavior_752014_2025-03-26_11-18-57\n",
      "Processing behavior_752014_2025-03-27_12-03-59\n",
      "Processing behavior_761038_2025-04-15_10-25-11\n",
      "Processing behavior_761038_2025-04-16_10-39-10\n",
      "Processing behavior_761038_2025-04-17_11-03-16\n",
      "Processing behavior_761038_2025-04-18_12-37-39\n"
     ]
    }
   ],
   "source": [
    "# loop through all sessions\n",
    "# count number of units pass qc and opto qc\n",
    "# check if exist in longer than 100 sessions \n",
    "# check if exist in pre/post stimulation\n",
    "# check if exist in anti-dromic stimulation\n",
    "all_sessions = []\n",
    "all_units = []\n",
    "all_qc_pass_units = [] # default qc pass\n",
    "all_real_units = [] # not noise, not artifact\n",
    "all_tagged_units = []\n",
    "in_behavior = []\n",
    "trial_count = []\n",
    "opto_tagging_pre = []\n",
    "opto_tagging_post = []\n",
    "anti = []\n",
    "probes = []\n",
    "all_p_max = []\n",
    "all_lat_max_p = []  # latency of max p response\n",
    "isi_v = []\n",
    "all_eu = []\n",
    "all_corr = []\n",
    "all_amp = []\n",
    "all_peak = []\n",
    "all_wf = []\n",
    "all_wf_aligned = []\n",
    "all_wf_2d = []\n",
    "y_loc = []\n",
    "in_df = []\n",
    "rec_side = []\n",
    "top = []\n",
    "bottom = []\n",
    "snr = []\n",
    "\n",
    "# p_resp_thresh = 0.5\n",
    "# lat_resp_thresh = 0.02\n",
    "\n",
    "target = 'soma'\n",
    "for session, beh in zip(session_ids, behs):\n",
    "    session_dir = session_dirs(session)\n",
    "    if session_dir['curated_dir_curated'] is not None:\n",
    "        if 'behavior_758017_2025-02-06_11-26-14' in session:\n",
    "            print('behavior_758017_2025-02-06_11-26-14')\n",
    "        print(f'Processing {session}')\n",
    "        data_type = 'curated'\n",
    "        # if session_dir['curated_dir_curated'] is not None:\n",
    "        #     data_type = 'curated'\n",
    "        # elif session_dir['curated_dir_raw'] is not None:\n",
    "        #     data_type = 'raw'\n",
    "        # else:\n",
    "        #     continue\n",
    "\n",
    "        unit_tbl = get_unit_tbl(session, data_type)\n",
    "        all_units.extend(unit_tbl['unit_id'].tolist())\n",
    "        all_qc_pass_units.extend(unit_tbl['default_qc'].tolist())  # default qc pass\n",
    "        # all_real_units.extend(unit_tbl['real_unit'].tolist())\n",
    "        all_tagged_units.extend(unit_tbl['tagged_loc'].tolist())  # tagged location (e.g. 'soma', 'axon', 'unspecified')\n",
    "        all_sessions.extend([session]*len(unit_tbl))\n",
    "        if 'p_max' not in unit_tbl.columns:\n",
    "            all_p_max.extend(unit_tbl['p_max_x'].tolist())\n",
    "            all_lat_max_p.extend(unit_tbl['lat_max_p_x'].tolist())\n",
    "            all_eu.extend(unit_tbl['euc_max_p_x'].tolist())\n",
    "            all_corr.extend(unit_tbl['corr_max_p_x'].tolist())\n",
    "            peaks = unit_tbl['peak_x'].values\n",
    "            amp = unit_tbl['amp_x'].values\n",
    "        else: \n",
    "            all_p_max.extend(unit_tbl['p_max'].tolist())  \n",
    "            all_lat_max_p.extend(unit_tbl['lat_max_p'].tolist()) \n",
    "            all_eu.extend(unit_tbl['euc_max_p'].tolist())\n",
    "            all_corr.extend(unit_tbl['corr_max_p'].tolist()) \n",
    "            peaks = unit_tbl['peak'].values\n",
    "            amp = unit_tbl['amp'].values\n",
    "     \n",
    "        isi_v.extend(unit_tbl['isi_violations_ratio'].tolist())  # ISI violations\n",
    "        snr.extend(unit_tbl['snr'].tolist())  # signal-to-noise ratio\n",
    "        y_loc.extend(unit_tbl['y_loc'].tolist())  # y location of the unit\n",
    "\n",
    "        top.extend(unit_tbl['LC_range_top'].tolist())\n",
    "        bottom.extend(unit_tbl['LC_range_bottom'].tolist())\n",
    "\n",
    "        # session and opto information\n",
    "        session_df = get_session_tbl(session)\n",
    "        with open(os.path.join(session_dir[f'opto_dir_{data_type}'], f'{session}_opto_info_{target}.json')) as f:\n",
    "            opto_info = json.load(f)\n",
    "        opto_df = pd.read_csv(os.path.join(session_dir[f'opto_dir_{data_type}'], f'{session}_opto_session_{target}.csv'))\n",
    "        if len(opto_df[opto_df['pre_post'] == 'pre'])>0:\n",
    "            pre_end = np.max(opto_df[opto_df['pre_post'] == 'pre']['time'].values)\n",
    "        else:\n",
    "            pre_end = np.nan\n",
    "        \n",
    "        if len(opto_df[opto_df['pre_post'] == 'post'])>0:\n",
    "            post_start = np.min(opto_df[opto_df['pre_post'] == 'post']['time'].values)\n",
    "            post_end = np.max(opto_df[opto_df['pre_post'] == 'post']['time'].values)\n",
    "        else:\n",
    "            post_start = np.nan\n",
    "            post_end = np.nan\n",
    "            \n",
    "        for unit_id in unit_tbl['unit_id'].values:\n",
    "            curr_pre_opto = True\n",
    "            curr_post_opto = True \n",
    "            curr_anti_opto = True  \n",
    "            if session_df is not None:\n",
    "                curr_in_beh = True\n",
    "            else:\n",
    "                curr_in_beh = False\n",
    "                curr_trial_count = 0\n",
    "            unit = unit_tbl[unit_tbl['unit_id'] == unit_id]\n",
    "            unit_drift = load_drift(session, unit_id, data_type=data_type)\n",
    "            if session_df is not None:\n",
    "                go_cue_times = session_df['goCue_start_time']\n",
    "                if unit_drift is not None:\n",
    "                    if unit_drift['ephys_cut'][0] is not None:\n",
    "                        if unit_drift['ephys_cut'][0] > pre_end - 2*60:\n",
    "                            curr_pre_opto = False \n",
    "                        go_cue_times = go_cue_times[go_cue_times >= unit_drift['ephys_cut'][0]]         \n",
    "                    if unit_drift['ephys_cut'][1] is not None:\n",
    "                        if unit_drift['ephys_cut'][1] < post_start + 2*60:\n",
    "                            curr_post_opto = False\n",
    "                        if unit_drift['ephys_cut'][1] < post_end + 2*60:\n",
    "                            curr_anti_opto = False\n",
    "                        go_cue_times = go_cue_times[go_cue_times <= unit_drift['ephys_cut'][1]]\n",
    "                if len(go_cue_times) < 100: \n",
    "                    curr_in_beh = False\n",
    "                curr_trial_count = len(go_cue_times)\n",
    "            opto_tagging_pre.append(curr_pre_opto)\n",
    "            opto_tagging_post.append(curr_post_opto)\n",
    "            anti.append(curr_anti_opto)\n",
    "            trial_count.append(curr_trial_count)\n",
    "            in_behavior.append(curr_in_beh)\n",
    "        probes.extend([df[df['session_id']==session]['probe'].values[0]] * len(unit_tbl))\n",
    "        rec_side.extend([df[df['session_id']==session]['side'].values[0]]*len(unit_tbl))  # recording side\n",
    "        in_df.extend([beh] * len(unit_tbl))  # store session df for each unit\n",
    "combined_tagged_units = pd.DataFrame({'session': all_sessions,\n",
    "                                        'unit': all_units,\n",
    "                                        'qc_pass': all_qc_pass_units,\n",
    "                                        'opto_tagged': all_tagged_units,\n",
    "                                        'opto_tagging_pre': opto_tagging_pre,\n",
    "                                        'opto_tagging_post': opto_tagging_post,\n",
    "                                        'anti': anti,\n",
    "                                        'in_df': in_behavior,\n",
    "                                        'trial_count': trial_count,\n",
    "                                        'p_max': all_p_max,\n",
    "                                        'lat_max_p': all_lat_max_p,\n",
    "                                        'isi_violations': isi_v,\n",
    "                                        'snr': snr,\n",
    "                                        'eu': all_eu,\n",
    "                                        'corr': all_corr,\n",
    "                                        'probe': probes,\n",
    "                                        'y_loc': y_loc, \n",
    "                                        'rec_side': rec_side,\n",
    "                                        'top': top,\n",
    "                                        'bottom': bottom,\n",
    "                                        })\n",
    "\n",
    "# save dataframe in combined folder\n",
    "with open(os.path.join('/root/capsule/scratch/combined/combine_unit_tbl', 'combined_unit_tbl.pkl'), 'wb') as f:\n",
    "    pickle.dump(combined_tagged_units, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
